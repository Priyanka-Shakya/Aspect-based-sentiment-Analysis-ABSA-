{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":4345109,"sourceType":"datasetVersion","datasetId":2546760},{"sourceId":11396111,"sourceType":"datasetVersion","datasetId":7137222},{"sourceId":12023973,"sourceType":"datasetVersion","datasetId":7564911},{"sourceId":12024084,"sourceType":"datasetVersion","datasetId":7564985}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:28:22.591776Z","iopub.execute_input":"2025-06-01T06:28:22.592424Z","iopub.status.idle":"2025-06-01T06:28:22.596757Z","shell.execute_reply.started":"2025-06-01T06:28:22.592399Z","shell.execute_reply":"2025-06-01T06:28:22.596102Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# A Novel Hybrid Deep Learning Model for Aspect-based sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"# Component-1(LSTM)","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom zipfile import ZipFile\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:28:52.091774Z","iopub.execute_input":"2025-06-01T06:28:52.092544Z","iopub.status.idle":"2025-06-01T06:29:05.499049Z","shell.execute_reply.started":"2025-06-01T06:28:52.092516Z","shell.execute_reply":"2025-06-01T06:29:05.498397Z"}},"outputs":[{"name":"stderr","text":"2025-06-01 06:28:54.177923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748759334.383350      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748759334.447800      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:30:27.062190Z","iopub.execute_input":"2025-06-01T06:30:27.062959Z","iopub.status.idle":"2025-06-01T06:30:28.562622Z","shell.execute_reply.started":"2025-06-01T06:30:27.062934Z","shell.execute_reply":"2025-06-01T06:30:28.561836Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:30:40.291650Z","iopub.execute_input":"2025-06-01T06:30:40.292366Z","iopub.status.idle":"2025-06-01T06:30:40.297402Z","shell.execute_reply.started":"2025-06-01T06:30:40.292342Z","shell.execute_reply":"2025-06-01T06:30:40.296741Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(50000, 2)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:30:53.311596Z","iopub.execute_input":"2025-06-01T06:30:53.312145Z","iopub.status.idle":"2025-06-01T06:30:53.331456Z","shell.execute_reply.started":"2025-06-01T06:30:53.312122Z","shell.execute_reply":"2025-06-01T06:30:53.330687Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:31:08.724322Z","iopub.execute_input":"2025-06-01T06:31:08.724679Z","iopub.status.idle":"2025-06-01T06:31:08.732129Z","shell.execute_reply.started":"2025-06-01T06:31:08.724656Z","shell.execute_reply":"2025-06-01T06:31:08.731571Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data[\"sentiment\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:31:32.733461Z","iopub.execute_input":"2025-06-01T06:31:32.733743Z","iopub.status.idle":"2025-06-01T06:31:32.745875Z","shell.execute_reply.started":"2025-06-01T06:31:32.733722Z","shell.execute_reply":"2025-06-01T06:31:32.745334Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    25000\nnegative    25000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:31:47.116925Z","iopub.execute_input":"2025-06-01T06:31:47.117210Z","iopub.status.idle":"2025-06-01T06:31:47.140621Z","shell.execute_reply.started":"2025-06-01T06:31:47.117189Z","shell.execute_reply":"2025-06-01T06:31:47.139897Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2568826810.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:32:00.711622Z","iopub.execute_input":"2025-06-01T06:32:00.712137Z","iopub.status.idle":"2025-06-01T06:32:00.718916Z","shell.execute_reply.started":"2025-06-01T06:32:00.712112Z","shell.execute_reply":"2025-06-01T06:32:00.718106Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment\n0  One of the other reviewers has mentioned that ...          1\n1  A wonderful little production. <br /><br />The...          1\n2  I thought this was a wonderful way to spend ti...          1\n3  Basically there's a family where a little boy ...          0\n4  Petter Mattei's \"Love in the Time of Money\" is...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"data[\"sentiment\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:32:16.516698Z","iopub.execute_input":"2025-06-01T06:32:16.517277Z","iopub.status.idle":"2025-06-01T06:32:16.524453Z","shell.execute_reply.started":"2025-06-01T06:32:16.517241Z","shell.execute_reply":"2025-06-01T06:32:16.523918Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"sentiment\n1    25000\n0    25000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# split data into training data and test data\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:32:31.693033Z","iopub.execute_input":"2025-06-01T06:32:31.693538Z","iopub.status.idle":"2025-06-01T06:32:31.707565Z","shell.execute_reply.started":"2025-06-01T06:32:31.693504Z","shell.execute_reply":"2025-06-01T06:32:31.706969Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:32:44.299070Z","iopub.execute_input":"2025-06-01T06:32:44.299780Z","iopub.status.idle":"2025-06-01T06:32:44.303750Z","shell.execute_reply.started":"2025-06-01T06:32:44.299754Z","shell.execute_reply":"2025-06-01T06:32:44.302975Z"}},"outputs":[{"name":"stdout","text":"(40000, 2)\n(10000, 2)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Tokenize text data\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(train_data[\"review\"])\nX_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=200)\nX_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:32:59.057072Z","iopub.execute_input":"2025-06-01T06:32:59.057759Z","iopub.status.idle":"2025-06-01T06:33:08.754408Z","shell.execute_reply.started":"2025-06-01T06:32:59.057735Z","shell.execute_reply":"2025-06-01T06:33:08.753463Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:33:18.273858Z","iopub.execute_input":"2025-06-01T06:33:18.274559Z","iopub.status.idle":"2025-06-01T06:33:18.278982Z","shell.execute_reply.started":"2025-06-01T06:33:18.274526Z","shell.execute_reply":"2025-06-01T06:33:18.278142Z"}},"outputs":[{"name":"stdout","text":"[[1935    1 1200 ...  205  351 3856]\n [   3 1651  595 ...   89  103    9]\n [   0    0    0 ...    2  710   62]\n ...\n [   0    0    0 ... 1641    2  603]\n [   0    0    0 ...  245  103  125]\n [   0    0    0 ...   70   73 2062]]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:33:30.156098Z","iopub.execute_input":"2025-06-01T06:33:30.156629Z","iopub.status.idle":"2025-06-01T06:33:30.160512Z","shell.execute_reply.started":"2025-06-01T06:33:30.156608Z","shell.execute_reply":"2025-06-01T06:33:30.159662Z"}},"outputs":[{"name":"stdout","text":"[[   0    0    0 ...  995  719  155]\n [  12  162   59 ...  380    7    7]\n [   0    0    0 ...   50 1088   96]\n ...\n [   0    0    0 ...  125  200 3241]\n [   0    0    0 ... 1066    1 2305]\n [   0    0    0 ...    1  332   27]]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"Y_train = train_data[\"sentiment\"]\nY_test = test_data[\"sentiment\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:33:42.111831Z","iopub.execute_input":"2025-06-01T06:33:42.112539Z","iopub.status.idle":"2025-06-01T06:33:42.116095Z","shell.execute_reply.started":"2025-06-01T06:33:42.112511Z","shell.execute_reply":"2025-06-01T06:33:42.115485Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(Y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:33:55.921204Z","iopub.execute_input":"2025-06-01T06:33:55.921481Z","iopub.status.idle":"2025-06-01T06:33:55.926628Z","shell.execute_reply.started":"2025-06-01T06:33:55.921461Z","shell.execute_reply":"2025-06-01T06:33:55.925831Z"}},"outputs":[{"name":"stdout","text":"39087    0\n30893    0\n45278    1\n16398    0\n13653    0\n        ..\n11284    1\n44732    1\n38158    0\n860      1\n15795    1\nName: sentiment, Length: 40000, dtype: int64\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# build the model\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=5000, output_dim=128, input_length=200))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation=\"sigmoid\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:34:10.032113Z","iopub.execute_input":"2025-06-01T06:34:10.032818Z","iopub.status.idle":"2025-06-01T06:34:11.318498Z","shell.execute_reply.started":"2025-06-01T06:34:10.032793Z","shell.execute_reply":"2025-06-01T06:34:11.317674Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1748759651.277680      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:34:22.276605Z","iopub.execute_input":"2025-06-01T06:34:22.276872Z","iopub.status.idle":"2025-06-01T06:34:22.289498Z","shell.execute_reply.started":"2025-06-01T06:34:22.276852Z","shell.execute_reply":"2025-06-01T06:34:22.288914Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:34:34.851590Z","iopub.execute_input":"2025-06-01T06:34:34.852317Z","iopub.status.idle":"2025-06-01T06:34:34.870170Z","shell.execute_reply.started":"2025-06-01T06:34:34.852295Z","shell.execute_reply":"2025-06-01T06:34:34.869487Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_split=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:35:37.672389Z","iopub.execute_input":"2025-06-01T06:35:37.672968Z","iopub.status.idle":"2025-06-01T06:48:46.924246Z","shell.execute_reply.started":"2025-06-01T06:35:37.672945Z","shell.execute_reply":"2025-06-01T06:48:46.923624Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\nEpoch 1/5\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 315ms/step - accuracy: 0.7289 - loss: 0.5292 - val_accuracy: 0.8054 - val_loss: 0.4277\nEpoch 2/5\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 313ms/step - accuracy: 0.8439 - loss: 0.3718 - val_accuracy: 0.8668 - val_loss: 0.3206\nEpoch 3/5\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 312ms/step - accuracy: 0.8757 - loss: 0.3078 - val_accuracy: 0.8651 - val_loss: 0.3338\nEpoch 4/5\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 311ms/step - accuracy: 0.8891 - loss: 0.2823 - val_accuracy: 0.8711 - val_loss: 0.3185\nEpoch 5/5\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 311ms/step - accuracy: 0.9058 - loss: 0.2362 - val_accuracy: 0.8509 - val_loss: 0.3839\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cc3ac0f1dd0>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, Y_test)\nprint(f\"Test Loss: {loss}\")\nprint(f\"Test Accuracy: {accuracy*100}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:49:12.285504Z","iopub.execute_input":"2025-06-01T06:49:12.285794Z","iopub.status.idle":"2025-06-01T06:49:42.710188Z","shell.execute_reply.started":"2025-06-01T06:49:12.285773Z","shell.execute_reply":"2025-06-01T06:49:42.709606Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.8499 - loss: 0.3733\nTest Loss: 0.36915823817253113\nTest Accuracy: 85.35000085830688\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Building a Predictive System","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(review):\n  # tokenize and pad the review\n  sequence = tokenizer.texts_to_sequences([review])\n  padded_sequence = pad_sequences(sequence, maxlen=200)\n  prediction = model.predict(padded_sequence)\n  sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n  return sentiment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:50:20.421718Z","iopub.execute_input":"2025-06-01T06:50:20.422315Z","iopub.status.idle":"2025-06-01T06:50:20.426031Z","shell.execute_reply.started":"2025-06-01T06:50:20.422291Z","shell.execute_reply":"2025-06-01T06:50:20.425410Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# example usage\nnew_review = \"This movie was fantastic. I loved it.\"\nsentiment = predict_sentiment(new_review)\nprint(f\"The sentiment of the review is: {sentiment}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:50:35.244284Z","iopub.execute_input":"2025-06-01T06:50:35.244844Z","iopub.status.idle":"2025-06-01T06:50:35.857625Z","shell.execute_reply.started":"2025-06-01T06:50:35.244826Z","shell.execute_reply":"2025-06-01T06:50:35.857034Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\nThe sentiment of the review is: positive\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Google Translate Implementation","metadata":{}},{"cell_type":"code","source":"!pip install googletrans==3.1.0a0\n!pip install langdetect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:52:46.077817Z","iopub.execute_input":"2025-06-01T06:52:46.078102Z","iopub.status.idle":"2025-06-01T06:53:00.453018Z","shell.execute_reply.started":"2025-06-01T06:52:46.078080Z","shell.execute_reply":"2025-06-01T06:53:00.452084Z"}},"outputs":[{"name":"stdout","text":"Collecting googletrans==3.1.0a0\n  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting httpx==0.13.3 (from googletrans==3.1.0a0)\n  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2025.4.26)\nCollecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\nCollecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\nCollecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\nCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\nCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\nCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\nCollecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\nDownloading httpx-0.13.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\nDownloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: googletrans\n  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16353 sha256=8deaa6b7c51004c7dd572df8b7c7940abeb027fa741b547e623d77a1839844ea\n  Stored in directory: /root/.cache/pip/wheels/81/f2/e0/d578821d723b473d18610ea93810e4a5402463919f07e603d9\nSuccessfully built googletrans\nInstalling collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n  Attempting uninstall: hyperframe\n    Found existing installation: hyperframe 6.1.0\n    Uninstalling hyperframe-6.1.0:\n      Successfully uninstalled hyperframe-6.1.0\n  Attempting uninstall: hpack\n    Found existing installation: hpack 4.1.0\n    Uninstalling hpack-4.1.0:\n      Successfully uninstalled hpack-4.1.0\n  Attempting uninstall: h11\n    Found existing installation: h11 0.14.0\n    Uninstalling h11-0.14.0:\n      Successfully uninstalled h11-0.14.0\n  Attempting uninstall: chardet\n    Found existing installation: chardet 5.2.0\n    Uninstalling chardet-5.2.0:\n      Successfully uninstalled chardet-5.2.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: h2\n    Found existing installation: h2 4.2.0\n    Uninstalling h2-4.2.0:\n      Successfully uninstalled h2-4.2.0\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.7\n    Uninstalling httpcore-1.0.7:\n      Successfully uninstalled httpcore-1.0.7\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.28.1\n    Uninstalling httpx-0.28.1:\n      Successfully uninstalled httpx-0.28.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nopenai 1.70.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\nlangsmith 0.3.23 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-genai 1.9.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\nCollecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=18628e3270b66fa5db4ae2c9aa57a07f261f5de1397da8b573ecfa8d85ad664b\n  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from googletrans import Translator\ntranslator = Translator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:53:24.500045Z","iopub.execute_input":"2025-06-01T06:53:24.500761Z","iopub.status.idle":"2025-06-01T06:53:24.649622Z","shell.execute_reply.started":"2025-06-01T06:53:24.500731Z","shell.execute_reply":"2025-06-01T06:53:24.649054Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from langdetect import detect, detect_langs\n\n# text = \"आप कैसे हैं\"\n# text = \"Movie achhi nhi hai\"\ntext = \"खाना अच्छा नहीं है\"\n\nlanguage = detect(text)\nprint(\"Detected Language:\", language)\n\n# confidence scores for multiple languages\nlanguages = detect_langs(text)\nprint(\"Possible Languages with Probabilities:\", languages)\nprint(languages[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:53:40.355834Z","iopub.execute_input":"2025-06-01T06:53:40.356403Z","iopub.status.idle":"2025-06-01T06:53:41.017993Z","shell.execute_reply.started":"2025-06-01T06:53:40.356379Z","shell.execute_reply":"2025-06-01T06:53:41.017353Z"}},"outputs":[{"name":"stdout","text":"Detected Language: hi\nPossible Languages with Probabilities: [hi:0.9999972581004233]\nhi:0.9999972581004233\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"source = language\ndestination = 'en'\ntranslated_output = translator.translate(text, src=source, dest=destination).text\nprint(\"Translated Output:\", translated_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:53:56.754998Z","iopub.execute_input":"2025-06-01T06:53:56.755277Z","iopub.status.idle":"2025-06-01T06:53:57.201333Z","shell.execute_reply.started":"2025-06-01T06:53:56.755256Z","shell.execute_reply":"2025-06-01T06:53:57.200647Z"}},"outputs":[{"name":"stdout","text":"Translated Output: Food is not good\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"sentiment = predict_sentiment(translated_output)\nprint(f\"The sentiment of the review is: {sentiment}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:54:12.441807Z","iopub.execute_input":"2025-06-01T06:54:12.442345Z","iopub.status.idle":"2025-06-01T06:54:12.621093Z","shell.execute_reply.started":"2025-06-01T06:54:12.442321Z","shell.execute_reply":"2025-06-01T06:54:12.620562Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\nThe sentiment of the review is: negative\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Implementing GAT Model","metadata":{}},{"cell_type":"markdown","source":"# Multilingual Dataset","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load JSON data\nwith open('/kaggle/input/train-data/train.json', 'r', encoding='utf-8') as file:\n    data = json.load(file)\n\n# List to hold flattened entries\nrows = []\n\n# Iterate over all entries\nfor entry in data:\n    # Reconstruct the full sentence from tokens\n    sentence = \" \".join(entry['token'])\n\n    # Extract aspects if present\n    for aspect in entry.get('aspects', []):\n        aspect_tokens = entry['token'][aspect['from']:aspect['to']]\n        aspect_term = \" \".join(aspect_tokens)\n        rows.append({\n            \"sentence\": sentence,\n            \"aspect_term\": aspect_term,\n            \"aspect_from\": aspect['from'],\n            \"aspect_to\": aspect['to'],\n            \"aspect_polarity\": aspect['polarity']\n        })\n\n# Convert to DataFrame\ndf = pd.DataFrame(rows)\n\n# Save to CSV\ndf.to_csv('new_dataset.csv', index=False, encoding='utf-8')\n\nprint(\"CSV conversion complete. Output saved as 'new_dataset.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:24:19.000625Z","iopub.execute_input":"2025-06-01T09:24:19.000910Z","iopub.status.idle":"2025-06-01T09:24:19.045763Z","shell.execute_reply.started":"2025-06-01T09:24:19.000889Z","shell.execute_reply":"2025-06-01T09:24:19.045213Z"}},"outputs":[{"name":"stdout","text":"CSV conversion complete. Output saved as 'new_dataset.csv'.\n","output_type":"stream"}],"execution_count":116},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:32:10.275548Z","iopub.execute_input":"2025-06-01T09:32:10.275825Z","iopub.status.idle":"2025-06-01T09:32:10.284059Z","shell.execute_reply.started":"2025-06-01T09:32:10.275805Z","shell.execute_reply":"2025-06-01T09:32:10.283536Z"}},"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"                                            sentence       aspect_term  \\\n0  I charge it at night and skip taking the cord ...              cord   \n1  I charge it at night and skip taking the cord ...      battery life   \n2  The tech guy then said the service center does...    service center   \n3  The tech guy then said the service center does...  `` sales '' team   \n4  The tech guy then said the service center does...          tech guy   \n\n   aspect_from  aspect_to aspect_polarity  \n0            9         10         neutral  \n1           16         18        positive  \n2            6          8        negative  \n3           22         26        negative  \n4            1          3         neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>aspect_term</th>\n      <th>aspect_from</th>\n      <th>aspect_to</th>\n      <th>aspect_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>9</td>\n      <td>10</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>16</td>\n      <td>18</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>6</td>\n      <td>8</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>`` sales '' team</td>\n      <td>22</td>\n      <td>26</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>1</td>\n      <td>3</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":117},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:32:39.280172Z","iopub.execute_input":"2025-06-01T09:32:39.280413Z","iopub.status.idle":"2025-06-01T09:32:39.284750Z","shell.execute_reply.started":"2025-06-01T09:32:39.280396Z","shell.execute_reply":"2025-06-01T09:32:39.284214Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"(2282, 5)"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"df.head(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:32:53.790273Z","iopub.execute_input":"2025-06-01T09:32:53.790920Z","iopub.status.idle":"2025-06-01T09:32:53.800638Z","shell.execute_reply.started":"2025-06-01T09:32:53.790893Z","shell.execute_reply":"2025-06-01T09:32:53.799958Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"                                            sentence       aspect_term  \\\n0  I charge it at night and skip taking the cord ...              cord   \n1  I charge it at night and skip taking the cord ...      battery life   \n2  The tech guy then said the service center does...    service center   \n3  The tech guy then said the service center does...  `` sales '' team   \n4  The tech guy then said the service center does...          tech guy   \n5  it is of high quality , has a killer GUI , is ...           quality   \n\n   aspect_from  aspect_to aspect_polarity  \n0            9         10         neutral  \n1           16         18        positive  \n2            6          8        negative  \n3           22         26        negative  \n4            1          3         neutral  \n5            4          5        positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>aspect_term</th>\n      <th>aspect_from</th>\n      <th>aspect_to</th>\n      <th>aspect_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>9</td>\n      <td>10</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>16</td>\n      <td>18</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>6</td>\n      <td>8</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>`` sales '' team</td>\n      <td>22</td>\n      <td>26</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>1</td>\n      <td>3</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>it is of high quality , has a killer GUI , is ...</td>\n      <td>quality</td>\n      <td>4</td>\n      <td>5</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"df.tail(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:33:07.970588Z","iopub.execute_input":"2025-06-01T09:33:07.971122Z","iopub.status.idle":"2025-06-01T09:33:07.977955Z","shell.execute_reply.started":"2025-06-01T09:33:07.971101Z","shell.execute_reply":"2025-06-01T09:33:07.977431Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n2276  We also use Paralles so we can run virtual mac...   \n2277  We also use Paralles so we can run virtual mac...   \n2278  We also use Paralles so we can run virtual mac...   \n2279  We also use Paralles so we can run virtual mac...   \n2280  How Toshiba handles the repair seems to vary ,...   \n2281  I would like to use a different operating syst...   \n\n                           aspect_term  aspect_from  aspect_to aspect_polarity  \n2276           Windows XP Professional           11         14         neutral  \n2277          , Windows 7 Home Premium           14         19         neutral  \n2278  , Windows Server Enterprise 2003           19         24         neutral  \n2279    Windows Server 2008 Enterprise           26         30         neutral  \n2280                            repair           25         26        positive  \n2281                  operating system            7          9         neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>aspect_term</th>\n      <th>aspect_from</th>\n      <th>aspect_to</th>\n      <th>aspect_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2276</th>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows XP Professional</td>\n      <td>11</td>\n      <td>14</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2277</th>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>, Windows 7 Home Premium</td>\n      <td>14</td>\n      <td>19</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2278</th>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>, Windows Server Enterprise 2003</td>\n      <td>19</td>\n      <td>24</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2279</th>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows Server 2008 Enterprise</td>\n      <td>26</td>\n      <td>30</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2280</th>\n      <td>How Toshiba handles the repair seems to vary ,...</td>\n      <td>repair</td>\n      <td>25</td>\n      <td>26</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2281</th>\n      <td>I would like to use a different operating syst...</td>\n      <td>operating system</td>\n      <td>7</td>\n      <td>9</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"df[\"aspect_polarity\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:33:22.090612Z","iopub.execute_input":"2025-06-01T09:33:22.091080Z","iopub.status.idle":"2025-06-01T09:33:22.097664Z","shell.execute_reply.started":"2025-06-01T09:33:22.091057Z","shell.execute_reply":"2025-06-01T09:33:22.097112Z"}},"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"aspect_polarity\npositive    976\nnegative    851\nneutral     455\nName: count, dtype: int64"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"df.replace({\"aspect_polarity\": {\"positive\": 1, \"negative\": -1, \"neutral\": 0}}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:33:37.750079Z","iopub.execute_input":"2025-06-01T09:33:37.750760Z","iopub.status.idle":"2025-06-01T09:33:37.756997Z","shell.execute_reply.started":"2025-06-01T09:33:37.750738Z","shell.execute_reply":"2025-06-01T09:33:37.756470Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3147649589.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df.replace({\"aspect_polarity\": {\"positive\": 1, \"negative\": -1, \"neutral\": 0}}, inplace=True)\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"df.head(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:33:51.616113Z","iopub.execute_input":"2025-06-01T09:33:51.616827Z","iopub.status.idle":"2025-06-01T09:33:51.624003Z","shell.execute_reply.started":"2025-06-01T09:33:51.616803Z","shell.execute_reply":"2025-06-01T09:33:51.623458Z"}},"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"                                            sentence       aspect_term  \\\n0  I charge it at night and skip taking the cord ...              cord   \n1  I charge it at night and skip taking the cord ...      battery life   \n2  The tech guy then said the service center does...    service center   \n3  The tech guy then said the service center does...  `` sales '' team   \n4  The tech guy then said the service center does...          tech guy   \n5  it is of high quality , has a killer GUI , is ...           quality   \n\n   aspect_from  aspect_to  aspect_polarity  \n0            9         10                0  \n1           16         18                1  \n2            6          8               -1  \n3           22         26               -1  \n4            1          3                0  \n5            4          5                1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>aspect_term</th>\n      <th>aspect_from</th>\n      <th>aspect_to</th>\n      <th>aspect_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>9</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>16</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>6</td>\n      <td>8</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>`` sales '' team</td>\n      <td>22</td>\n      <td>26</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>it is of high quality , has a killer GUI , is ...</td>\n      <td>quality</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":123},{"cell_type":"markdown","source":"# Multi-language Convertions","metadata":{}},{"cell_type":"code","source":"!pip install deep-translator pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:34:32.750587Z","iopub.execute_input":"2025-06-01T09:34:32.750825Z","iopub.status.idle":"2025-06-01T09:34:36.106080Z","shell.execute_reply.started":"2025-06-01T09:34:32.750809Z","shell.execute_reply":"2025-06-01T09:34:36.105394Z"}},"outputs":[{"name":"stdout","text":"Collecting deep-translator\n  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep-translator) (4.13.3)\nRequirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep-translator) (2.32.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nDownloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: deep-translator\nSuccessfully installed deep-translator-1.11.4\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"import pandas as pd\nfrom deep_translator import GoogleTranslator\nimport random\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/laptop-dataset-multilingual/new_dataset.csv\")  # Replace with your actual file\n\n# Translation function\ndef translate_to_hindi(text):\n    if isinstance(text, str) and text.strip():\n        try:\n            return GoogleTranslator(source='en', target='hi').translate(text)\n        except Exception as e:\n            print(f\"Translation failed for: {text} | Error: {e}\")\n            return text\n    return text\n\n# Initialize columns with blank values\ndf['sentence_translated'] = \"\"\ndf['aspect_term_translated'] = \"\"\n\n# Calculate 10% of the total rows (at least 1)\nsample_size = max(1, len(df) // 10)\n\n# Randomly select row indices to translate\nrows_to_translate = random.sample(range(len(df)), sample_size)\n\n# Apply translation to selected rows\nfor idx in rows_to_translate:\n    df.at[idx, 'sentence_translated'] = translate_to_hindi(df.at[idx, 'sentence'])\n    df.at[idx, 'aspect_term_translated'] = translate_to_hindi(df.at[idx, 'aspect_term'])\n\n# Save to a new CSV (optional)\ndf.to_csv(\"translated_subset.csv\", index=False)\n\n# Print translated rows as a check\nprint(df.loc[rows_to_translate, ['sentence', 'sentence_translated', 'aspect_term', 'aspect_term_translated']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:41:21.575541Z","iopub.execute_input":"2025-06-01T09:41:21.576125Z","iopub.status.idle":"2025-06-01T09:47:04.620702Z","shell.execute_reply.started":"2025-06-01T09:41:21.576104Z","shell.execute_reply":"2025-06-01T09:47:04.619792Z"}},"outputs":[{"name":"stdout","text":"Translation failed for: It 's still beautiful and has better color reproduction than I could ever expect from a notebook . | Error: It 's still beautiful and has better color reproduction than I could ever expect from a notebook . --> No translation was found using the current translator. Try another translator?\n                                               sentence  \\\n1577  It gives me the power and speed that I need to...   \n1722  Garageband is easy to work with , like all the...   \n165   BEST BUY - 5 STARS + + + ( sales , service , r...   \n1060  The only downfall is a lot of the software I h...   \n2094  The 13 '' Macbook Pro just fits in my budget a...   \n...                                                 ...   \n58    Drivers updated ok but the BIOS update froze t...   \n9     Easy to start up and does not overheat as much...   \n2164  3 weeks went by and the computer keeps crashin...   \n400   So what if the laptops/mobile phones look chic...   \n780   The screen is bright and clear , the operating...   \n\n                                    sentence_translated          aspect_term  \\\n1577  यह मुझे वह शक्ति और गति देता है जिसे मुझे संपा...             programs   \n1722  गैराजबैंड के साथ काम करना आसान है, जैसे कि अन्...   apple applications   \n165   सर्वश्रेष्ठ खरीदें - 5 स्टार + + + + (बिक्री, ...         DELL SUPPORT   \n1060  एकमात्र डाउनफॉल बहुत सारे सॉफ्टवेयर है जो मैंन...                iWork   \n2094  13 '' मैकबुक प्रो सिर्फ मेरे बजट में फिट बैठता...             shipping   \n...                                                 ...                  ...   \n58    ड्राइवरों ने अद्यतन किया, लेकिन BIOS अपडेट सिस...          BIOS update   \n9     शुरू करने के लिए आसान है और अन्य लैपटॉप के रूप...             start up   \n2164  3 सप्ताह बीत गए और कंप्यूटर दुर्घटनाग्रस्त रहत...         applications   \n400   तो क्या होगा अगर लैपटॉप/मोबाइल फोन ठाठ और शांत...  after sales support   \n780   स्क्रीन उज्ज्वल और स्पष्ट है, ऑपरेटिंग सिस्टम ...               screen   \n\n     aspect_term_translated  \n1577            कार्यक्रमों  \n1722        ऐप्पल अनुप्रयोग  \n165              डेल सपोर्ट  \n1060       मैं काम करता हूँ  \n2094                 शिपिंग  \n...                     ...  \n58             बायोस अद्यतन  \n9                 चालू होना  \n2164              अनुप्रयोग  \n400           बिक्री के बाद  \n780                 स्क्रीन  \n\n[228 rows x 4 columns]\n","output_type":"stream"}],"execution_count":126},{"cell_type":"code","source":"import pandas as pd\nfrom deep_translator import GoogleTranslator\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/laptop-dataset-multilingual/new_dataset.csv\")  # Replace with your file path\n\n# Function to translate text from English to Hindi\ndef translate_to_hindi(text):\n    if isinstance(text, str) and text.strip():\n        try:\n            return GoogleTranslator(source='en', target='hi').translate(text)\n        except Exception as e:\n            print(f\"Translation error: {e} | Text: {text}\")\n            return text\n    return text\n\n# Translate and replace the first 2 rows\nfor idx in range(min(2, len(df))):\n    df.at[idx, 'sentence'] = translate_to_hindi(df.at[idx, 'sentence'])\n    df.at[idx, 'aspect_term'] = translate_to_hindi(df.at[idx, 'aspect_term'])\n\n# Save the updated dataset (optional)\ndf.to_csv(\"dataset_translated_first2rows.csv\", index=False)\n\n# Display the first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:55:50.375378Z","iopub.execute_input":"2025-06-01T09:55:50.376222Z","iopub.status.idle":"2025-06-01T09:55:50.682618Z","shell.execute_reply.started":"2025-06-01T09:55:50.376186Z","shell.execute_reply":"2025-06-01T09:55:50.681960Z"}},"outputs":[{"name":"stdout","text":"                                            sentence       aspect_term  \\\n0  मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...             घिसना   \n1  मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...      बैटरी की आयु   \n2  The tech guy then said the service center does...    service center   \n3  The tech guy then said the service center does...  `` sales '' team   \n4  The tech guy then said the service center does...          tech guy   \n\n   aspect_from  aspect_to aspect_polarity  \n0            9         10         neutral  \n1           16         18        positive  \n2            6          8        negative  \n3           22         26        negative  \n4            1          3         neutral  \n","output_type":"stream"}],"execution_count":128},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:56:29.625746Z","iopub.execute_input":"2025-06-01T09:56:29.626019Z","iopub.status.idle":"2025-06-01T09:56:29.634295Z","shell.execute_reply.started":"2025-06-01T09:56:29.625999Z","shell.execute_reply":"2025-06-01T09:56:29.633543Z"}},"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"                                            sentence       aspect_term  \\\n0  मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...             घिसना   \n1  मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...      बैटरी की आयु   \n2  The tech guy then said the service center does...    service center   \n3  The tech guy then said the service center does...  `` sales '' team   \n4  The tech guy then said the service center does...          tech guy   \n\n   aspect_from  aspect_to aspect_polarity  \n0            9         10         neutral  \n1           16         18        positive  \n2            6          8        negative  \n3           22         26        negative  \n4            1          3         neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>aspect_term</th>\n      <th>aspect_from</th>\n      <th>aspect_to</th>\n      <th>aspect_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...</td>\n      <td>घिसना</td>\n      <td>9</td>\n      <td>10</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>मैं इसे रात में चार्ज करता हूं और अच्छी बैटरी ...</td>\n      <td>बैटरी की आयु</td>\n      <td>16</td>\n      <td>18</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>6</td>\n      <td>8</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>`` sales '' team</td>\n      <td>22</td>\n      <td>26</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>1</td>\n      <td>3</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":129},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom deep_translator import GoogleTranslator\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/laptop-dataset-multilingual/new_dataset.csv\")  # Replace with actual file path\n\n# Define language codes and their names for reference (optional)\nlanguages = {\n    'hi': 'Hindi',\n    'pa': 'Punjabi',\n    'zh-CN': 'Chinese',\n    'mr': 'Marathi',\n    'it': 'Italian',\n    'ja': 'Japanese'\n}\n\n# Function to translate text to the specified language\ndef translate_text(text, target_lang):\n    if isinstance(text, str) and text.strip():\n        try:\n            return GoogleTranslator(source='en', target=target_lang).translate(text)\n        except Exception as e:\n            print(f\"Error translating text: '{text}' to {target_lang} | {e}\")\n            return text\n    return text\n\n# Pick 1000 unique random indices from the dataset\nrandom_indices = random.sample(range(len(df)), 1000)\n\n# Translate the selected rows\nfor idx in random_indices:\n    lang = random.choice(list(languages.keys()))\n    df.at[idx, 'sentence'] = translate_text(df.at[idx, 'sentence'], lang)\n    df.at[idx, 'aspect_term'] = translate_text(df.at[idx, 'aspect_term'], lang)\n\n# Save the updated dataset\ndf.to_csv(\"multilingual_translated_dataset.csv\", index=False)\n\n# Optional: preview a few translated rows\nprint(df.loc[random_indices[:5], ['sentence', 'aspect_term']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:59:23.076214Z","iopub.execute_input":"2025-06-01T09:59:23.076516Z","iopub.status.idle":"2025-06-01T10:24:25.535657Z","shell.execute_reply.started":"2025-06-01T09:59:23.076495Z","shell.execute_reply":"2025-06-01T10:24:25.534972Z"}},"outputs":[{"name":"stdout","text":"Error translating text: ', ran' to ja | , ran --> No translation was found using the current translator. Try another translator?\n                                               sentence  \\\n487       彼らはジャンクであり、保証会社は恐ろしいゲートウェイコンピューターを購入しないでください。   \n813   इसमें कई महान कार्यक्रम हैं, जैसे कि ILife, iP...   \n1238       त्यांनी एक सोनी 'प्रमाणित' तंत्रज्ञ पाठविला.   \n1146  Funzionalità come la dashboard (consente di vi...   \n746   यह अभी भी काम कर रहा था, लेकिन स्क्रीन पर कुछ ...   \n\n                   aspect_term  \n487                       保証会社  \n813                कार्यक्रमों  \n1238  सोनी 'प्रमाणित' तंत्रज्ञ  \n1146     Pannello di controllo  \n746                    स्क्रीन  \n","output_type":"stream"}],"execution_count":130},{"cell_type":"markdown","source":"# GAT Model","metadata":{}},{"cell_type":"code","source":"import pickle\n\n\nclass Vocab(object):\n    def __init__(self, counter, specials=[\"<pad>\", \"<unk>\"]):\n        self.pad_index = 0\n        self.unk_index = 1\n        counter = counter.copy()\n        self.itos = list(specials)\n        for tok in specials:\n            del counter[tok]\n\n        # sort by frequency, then alphabetically\n        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n\n        for word, _ in words_and_frequencies:\n            self.itos.append(word)\n\n        # stoi is simply a reverse dict for itos\n        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n\n    def __eq__(self, other):\n        if self.stoi != other.stoi:\n            return False\n        if self.itos != other.itos:\n            return False\n        return True\n\n    def __len__(self):\n        return len(self.itos)\n\n    def extend(self, v):\n        words = v.itos\n        for w in words:\n            if w not in self.stoi:\n                self.itos.append(w)\n                self.stoi[w] = len(self.itos) - 1\n        return self\n\n    @staticmethod\n    def load_vocab(vocab_path: str):\n        with open(vocab_path, \"rb\") as f:\n            print('Loading vocab from:', vocab_path)\n            return pickle.load(f)\n\n    def save_vocab(self, vocab_path):\n        with open(vocab_path, \"wb\") as f:\n            print('Saving vocab to:', vocab_path)\n            pickle.dump(self, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:13:30.818013Z","iopub.execute_input":"2025-06-01T08:13:30.818322Z","iopub.status.idle":"2025-06-01T08:13:30.826111Z","shell.execute_reply.started":"2025-06-01T08:13:30.818300Z","shell.execute_reply":"2025-06-01T08:13:30.825485Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"import json\nimport os\nfrom collections import Counter\nimport pickle\n\n\n# Define a simple Vocab class if you don't have one\nclass Vocab:\n    def __init__(self, counter, specials=[]):\n        # self.vocab = {word: idx for idx, (word, _) in enumerate(counter.most_common())}\n        # self.vocab.update({special: idx for idx, special in enumerate(specials, len(self.vocab))})\n        # self.idx2word = {idx: word for word, idx in self.vocab.items()}\n        self.pad_index = 0\n        self.unk_index = 1\n        counter = counter.copy()\n        self.itos = list(specials)\n        for tok in specials:\n            del counter[tok]\n\n        # sort by frequency, then alphabetically\n        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n\n        for word, _ in words_and_frequencies:\n            self.itos.append(word)\n\n        # stoi is simply a reverse dict for itos\n        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n        \n    def __len__(self):\n        return len(self.itos)\n\n    def __eq__(self, other):\n        if self.stoi != other.stoi:\n            return False\n        if self.itos != other.itos:\n            return False\n        return True\n\n    @staticmethod\n    def load_vocab(vocab_path: str):\n        with open(vocab_path, \"rb\") as f:\n            print('Loading vocab from:', vocab_path)\n            return pickle.load(f)\n            \n    def save_vocab(self, vocab_path):\n        # with open(vocab_path, \"w\") as f:  # Use \"w\" mode to save as a text file\n        #     print('Saving vocab to:', vocab_path)\n        #     for word, idx in self.vocab.items():\n        #         f.write(f\"{word}\\t{idx}\\n\")\n        with open(vocab_path, \"wb\") as f:\n            print('Saving vocab to:', vocab_path)\n            pickle.dump(self, f)\n            \n\ndef main():\n    # Define paths manually (change as needed)\n    data_dir = \"/kaggle/input/laptop-dataset\"  # Replace with your data directory in Kaggle\n    vocab_dir = \"/kaggle/working/vocab/laptop-dataset\"  # Replace with desired output directory in Kaggle\n    \n    # Ensure the vocab directory exists\n    if not os.path.exists(vocab_dir):\n        os.makedirs(vocab_dir)\n\n    # input files\n    train_file = f\"{data_dir}/train.json\"\n    test_file = f\"{data_dir}/test.json\"\n\n    # output files\n    vocab_tok_file = f\"{vocab_dir}/vocab_tok.vocab\"\n    vocab_post_file = f\"{vocab_dir}/vocab_post.vocab\"\n    vocab_pos_file = f\"{vocab_dir}/vocab_pos.vocab\"\n    vocab_dep_file = f\"{vocab_dir}/vocab_dep.vocab\"\n    vocab_pol_file = f\"{vocab_dir}/vocab_pol.vocab\"\n\n    # Load files\n    print(\"loading files...\")\n    train_tokens, train_pos, train_dep, train_max_len = load_tokens(train_file)\n    test_tokens, test_pos, test_dep, test_max_len = load_tokens(test_file)\n\n    # Lower tokens\n    train_tokens, test_tokens = [\n        [t.lower() for t in tokens] for tokens in (train_tokens, test_tokens)\n    ]\n    \n    # Counters\n    token_counter = Counter(train_tokens + test_tokens)\n    pos_counter = Counter(train_pos + test_pos)\n    dep_counter = Counter(train_dep + test_dep)\n    max_len = max(train_max_len, test_max_len)\n    post_counter = Counter(list(range(-max_len, max_len)))\n    pol_counter = Counter([\"positive\", \"negative\", \"neutral\"])\n\n\n     # Build vocab\n    print(\"building vocab...\")\n    token_vocab = Vocab(token_counter, specials=[\"<pad>\", \"<unk>\"])\n    pos_vocab = Vocab(pos_counter, specials=[\"<pad>\", \"<unk>\"])\n    dep_vocab = Vocab(dep_counter, specials=[\"<pad>\", \"<unk>\", \"<self>\"])\n    post_vocab = Vocab(post_counter, specials=[\"<pad>\", \"<unk>\"])\n    pol_vocab = Vocab(pol_counter, specials=[])\n    print(\n        f\"token_vocab: {len(token_vocab)}, pos_vocab: {len(pos_vocab)}, dep_vocab: {len(dep_vocab)}, \"\n        f\"post_vocab: {len(post_vocab)}, pol_vocab: {len(pol_vocab)}\"\n    )\n\n    print(\"dumping to files...\")\n    token_vocab.save_vocab(vocab_tok_file)\n    pos_vocab.save_vocab(vocab_pos_file)\n    dep_vocab.save_vocab(vocab_dep_file)\n    post_vocab.save_vocab(vocab_post_file)\n    pol_vocab.save_vocab(vocab_pol_file)\n    print(\"all done.\")\n\ndef load_tokens(filename):\n    with open(filename) as infile:\n        data = json.load(infile)\n        tokens = []\n        pos = []\n        dep = []\n        max_len = 0\n        for d in data:\n            tokens.extend(d[\"token\"])\n            pos.extend(d[\"pos\"])\n            dep.extend(d[\"deprel\"])\n            max_len = max(len(d[\"token\"]), max_len)\n    print(f\"{len(tokens)} tokens from {len(data)} examples loaded from {filename}.\")\n    return tokens, pos, dep, max_len\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:18:15.642739Z","iopub.execute_input":"2025-06-01T08:18:15.643009Z","iopub.status.idle":"2025-06-01T08:18:15.716493Z","shell.execute_reply.started":"2025-06-01T08:18:15.642989Z","shell.execute_reply":"2025-06-01T08:18:15.715865Z"}},"outputs":[{"name":"stdout","text":"loading files...\n28476 tokens from 1454 examples loaded from /kaggle/input/laptop-dataset/train.json.\n6510 tokens from 409 examples loaded from /kaggle/input/laptop-dataset/test.json.\nbuilding vocab...\ntoken_vocab: 3525, pos_vocab: 46, dep_vocab: 34, post_vocab: 168, pol_vocab: 3\ndumping to files...\nSaving vocab to: /kaggle/working/vocab/laptop-dataset/vocab_tok.vocab\nSaving vocab to: /kaggle/working/vocab/laptop-dataset/vocab_pos.vocab\nSaving vocab to: /kaggle/working/vocab/laptop-dataset/vocab_dep.vocab\nSaving vocab to: /kaggle/working/vocab/laptop-dataset/vocab_post.vocab\nSaving vocab to: /kaggle/working/vocab/laptop-dataset/vocab_pol.vocab\nall done.\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# encoding=utf-8\nimport sys\n# sys.path.append('../')\nimport torch\nimport random\nimport argparse\nimport numpy as np\n# from vocab import Vocab\n# from utils import helper\nfrom sklearn import metrics\n# from loader import ABSADataLoader\n# from model import RGATABSA\n# from trainer import ABSATrainer\n# from load_w2v import load_pretrained_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:18:37.873428Z","iopub.execute_input":"2025-06-01T08:18:37.873720Z","iopub.status.idle":"2025-06-01T08:18:37.877196Z","shell.execute_reply.started":"2025-06-01T08:18:37.873700Z","shell.execute_reply":"2025-06-01T08:18:37.876578Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def get_optimizer(name, parameters, lr, l2=0):\n    if name == 'sgd':\n        return torch.optim.SGD(parameters, lr=lr, weight_decay=l2)\n    elif name == 'adagrad':\n        return torch.optim.Adagrad(parameters, lr=lr, weight_decay=l2)\n    elif name == 'adam':\n        return torch.optim.Adam(parameters, lr=lr, weight_decay=l2) \n    elif name == 'adamax':\n        return torch.optim.Adamax(parameters, lr=lr, weight_decay=l2) \n    elif name == 'adadelta':\n        return torch.optim.Adadelta(parameters, lr=lr, weight_decay=l2)\n    else:\n        raise Exception(\"Unsupported optimizer: {}\".format(name))\n\n# load args config\ndef load_config(filename):\n    try:\n        dump = torch.load(filename)\n    except BaseException:\n        print(\"[ Fail: model loading failed. ]\")\n    return dump['config']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:27:09.370618Z","iopub.execute_input":"2025-06-01T08:27:09.370884Z","iopub.status.idle":"2025-06-01T08:27:09.376086Z","shell.execute_reply.started":"2025-06-01T08:27:09.370865Z","shell.execute_reply":"2025-06-01T08:27:09.375453Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\n\nclass ABSATrainer(object):\n    def __init__(self, args, emb_matrix=None):\n        self.args = args\n        self.emb_matrix = emb_matrix\n        self.model = RGATABSA(args, emb_matrix=emb_matrix)\n        self.parameters = [p for p in self.model.parameters() if p.requires_grad]\n        self.model.cuda()\n        self.optimizer = get_optimizer(args.optim, self.parameters, args.lr)\n\n    # Load model_state and args\n    def load(self, filename):\n        try:\n            checkpoint = torch.load(filename)\n        except BaseException:\n            print(\"Cannot load model from {}\".format(filename))\n            exit()\n        self.model.load_state_dict(checkpoint['model'])\n        self.args = checkpoint['config']\n\n    # Save model_state and args\n    def save(self, filename):\n        params = {\n            'model': self.model.state_dict(),\n            'config': self.args,\n        }\n        try:\n            torch.save(params, filename)\n            print(\"Model saved to {}\".format(filename))\n        except BaseException:\n            print(\"[Warning: Saving failed... continuing anyway.]\")\n\n    def update(self, batch):\n        # Convert to CUDA\n        batch = [b.cuda() for b in batch]\n\n        # Unpack inputs and label\n        inputs = batch[0:8]\n        label = batch[-1]\n\n        # Step forward\n        self.model.train()\n        self.optimizer.zero_grad()\n        logits, _ = self.model(inputs)\n        loss = F.cross_entropy(logits, label, reduction='mean')\n        corrects = (torch.max(logits, 1)[1].view(label.size()).data == label.data).sum()\n        acc = 100.0 * float(corrects) / label.size()[0]\n\n        # Backward\n        loss.backward()\n        self.optimizer.step()\n        return loss.data, acc\n\n    def predict(self, batch):\n        # Convert to CUDA\n        batch = [b.cuda() for b in batch]\n\n        # Unpack inputs and label\n        inputs = batch[0:8]\n        label = batch[-1]\n\n        # Forward\n        self.model.eval()\n        logits, g_outputs = self.model(inputs)\n        loss = F.cross_entropy(logits, label, reduction='mean')\n        corrects = (torch.max(logits, 1)[1].view(label.size()).data == label.data).sum()\n        acc = 100.0 * float(corrects) / label.size()[0]\n        predictions = np.argmax(logits.data.cpu().numpy(), axis=1).tolist()\n        predprob = F.softmax(logits, dim=1).data.cpu().numpy().tolist()\n\n        return (\n            loss.data,\n            acc,\n            predictions,\n            label.data.cpu().numpy().tolist(),\n            predprob,\n            g_outputs.data.cpu().numpy()\n        )\n\n    def show_error(self, batch, vocab=None):\n        # Convert to CUDA\n        batch = [b.cuda() for b in batch]\n\n        # Unpack inputs and label\n        inputs = batch[0:8]\n        label = batch[-1]\n\n        # Forward\n        self.model.eval()\n        logits, g_outputs = self.model(inputs)\n        loss = F.cross_entropy(logits, label, reduction='mean')\n        corrects = (torch.max(logits, 1)[1].view(label.size()).data == label.data).sum()\n        acc = 100.0 * float(corrects) / label.size()[0]\n        predictions = np.argmax(logits.data.cpu().numpy(), axis=1).tolist()\n        predprob = F.softmax(logits, dim=1).data.cpu().numpy().tolist()\n\n        for i in range(len(batch)):\n            tokids = batch[0][i]\n            aspids = batch[1][i]\n            ithlabel = batch[-1][i]\n            pridict = predictions[i]\n\n            if vocab is not None:\n                tok = [vocab.itos[idx] for idx in tokids]\n                asp_tok = [vocab.itos[idx] for idx in aspids]\n                strline = '{} {} {} {} {}'.format(\n                    ' '.join(tok),\n                    ' '.join(asp_tok),\n                    ithlabel.item(),\n                    pridict,\n                    ithlabel.item() == pridict\n                )\n                print(strline)\n\n        return (\n            loss.data,\n            acc,\n            predictions,\n            label.data.cpu().numpy().tolist(),\n            predprob,\n            g_outputs.data.cpu().numpy()\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:29:23.090202Z","iopub.execute_input":"2025-06-01T08:29:23.090489Z","iopub.status.idle":"2025-06-01T08:29:23.104725Z","shell.execute_reply.started":"2025-06-01T08:29:23.090470Z","shell.execute_reply":"2025-06-01T08:29:23.104245Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:29:42.230271Z","iopub.execute_input":"2025-06-01T08:29:42.230899Z","iopub.status.idle":"2025-06-01T08:29:42.233555Z","shell.execute_reply.started":"2025-06-01T08:29:42.230877Z","shell.execute_reply":"2025-06-01T08:29:42.232993Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def head_to_adj(sent_len, head, tokens, label, len_, mask, directed=False, self_loop=True):\n    \"\"\"\n    Convert a sequence of head indexes into a 0/1 adjacency matrix and label matrix.\n    \"\"\"\n    adj_matrix = np.zeros((sent_len, sent_len), dtype=np.float32)\n    label_matrix = np.zeros((sent_len, sent_len), dtype=np.int64)\n\n    assert not isinstance(head, list)\n    tokens = tokens[:len_].tolist()\n    head = head[:len_].tolist()\n    label = label[:len_].tolist()\n\n    asp_idx = [idx for idx in range(len(mask)) if mask[idx] == 1]\n\n    for idx, h in enumerate(head):\n        if idx in asp_idx:\n            for k in asp_idx:\n                adj_matrix[idx][k] = 1\n                label_matrix[idx][k] = 2\n\n        if h != 0:\n            adj_matrix[idx, h - 1] = 1\n            label_matrix[idx, h - 1] = label[idx]\n        else:\n            if self_loop:\n                adj_matrix[idx, idx] = 1\n                label_matrix[idx, idx] = 2\n                continue\n\n        if not directed:\n            adj_matrix[h - 1, idx] = 1\n            label_matrix[h - 1, idx] = label[idx]\n\n        if self_loop:\n            adj_matrix[idx, idx] = 1\n            label_matrix[idx, idx] = 2\n\n    return adj_matrix, label_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:31:05.740844Z","iopub.execute_input":"2025-06-01T08:31:05.741356Z","iopub.status.idle":"2025-06-01T08:31:05.750457Z","shell.execute_reply.started":"2025-06-01T08:31:05.741329Z","shell.execute_reply":"2025-06-01T08:31:05.749809Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"from torch.autograd import Variable\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass RGATABSA(nn.Module):\n    def __init__(self, args, emb_matrix=None):\n        super().__init__()\n        in_dim = args.hidden_dim\n        self.args = args\n        self.enc = ABSAEncoder(args, emb_matrix=emb_matrix)\n        self.classifier = nn.Linear(in_dim, args.num_class)\n\n    def forward(self, inputs):\n        hiddens = self.enc(inputs)\n        logits = self.classifier(hiddens)\n        return logits, hiddens\n\n\nclass ABSAEncoder(nn.Module):\n    def __init__(self, args, emb_matrix=None):\n        super().__init__()\n        self.args = args\n        self.emb_matrix = emb_matrix\n\n        # #################### Embeddings ###################\n        self.emb = nn.Embedding(args.tok_size, args.emb_dim, padding_idx=0)\n        if emb_matrix is not None:\n            self.emb.weight = nn.Parameter(emb_matrix.cuda(), requires_grad=False)\n\n        self.pos_emb = (\n            nn.Embedding(args.pos_size, args.pos_dim, padding_idx=0)\n            if args.pos_dim > 0 else None\n        )\n        self.post_emb = (\n            nn.Embedding(args.post_size, args.post_dim, padding_idx=0)\n            if args.post_dim > 0 else None\n        )\n\n        # #################### Encoder ###################\n        if self.args.model.lower() in [\"std\", \"gat\"]:\n            embeddings = (self.emb, self.pos_emb, self.post_emb)\n            self.encoder = DoubleEncoder(args, embeddings, args.hidden_dim, args.num_layers)\n        elif self.args.model.lower() == \"rgat\":\n            self.dep_emb = (\n                nn.Embedding(args.dep_size, args.dep_dim, padding_idx=0)\n                if args.dep_dim > 0 else None\n            )\n            embeddings = (self.emb, self.pos_emb, self.post_emb, self.dep_emb)\n            self.encoder = DoubleEncoder(args, embeddings, args.hidden_dim, args.num_layers, use_dep=True)\n        else:\n            print(f\"Invalid model name {self.args.model.lower()}, it should be (std, GAT, RGAT)\")\n            exit(0)\n\n        # #################### pooling and fusion modules ###################\n        if self.args.pooling.lower() == \"attn\":\n            self.attn = torch.nn.Linear(args.hidden_dim, 1)\n\n        if self.args.output_merge.lower() != \"none\":\n            self.inp_map = torch.nn.Linear(args.hidden_dim * 2, args.hidden_dim)\n\n        if self.args.output_merge.lower() == \"attn\":\n            self.out_attn_map = torch.nn.Linear(args.hidden_dim * 2, 1)\n        elif self.args.output_merge.lower() == \"gate\":\n            self.out_gate_map = torch.nn.Linear(args.hidden_dim * 2, args.hidden_dim)\n        elif self.args.output_merge.lower() in [\"gatenorm\", \"gatenorm2\"]:\n            self.out_gate_map = torch.nn.Linear(args.hidden_dim * 2, args.hidden_dim)\n            self.out_norm = nn.LayerNorm(args.hidden_dim)\n        elif self.args.output_merge.lower() == \"addnorm\":\n            self.out_norm = nn.LayerNorm(args.hidden_dim)\n        elif self.args.output_merge.lower() not in [\"none\", \"add\"]:\n            print(\"Invalid output_merge type: \", self.args.output_merge)\n            exit()\n\n        if self.args.output_merge.lower() != \"none\":\n            self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.eye_(self.inp_map.weight)\n        torch.nn.init.zeros_(self.inp_map.bias)\n\n    def forward(self, inputs):\n        tok, asp, pos, head, deprel, post, mask_ori, lengths = inputs\n        maxlen = max(lengths.data)\n\n        adj_lst, label_lst = [], []\n        for idx in range(len(lengths)):\n            adj_i, label_i = head_to_adj(\n                maxlen, head[idx], tok[idx], deprel[idx], lengths[idx], mask_ori[idx],\n                directed=self.args.direct, self_loop=self.args.loop\n            )\n            adj_lst.append(adj_i.reshape(1, maxlen, maxlen))\n            label_lst.append(label_i.reshape(1, maxlen, maxlen))\n\n        adj = np.concatenate(adj_lst, axis=0)\n        adj = torch.from_numpy(adj).cuda()\n\n        labels = np.concatenate(label_lst, axis=0)\n        label_all = torch.from_numpy(labels).cuda()\n\n        if self.args.model.lower() == \"std\":\n            sent_out, graph_out = self.encoder(adj=None, inputs=inputs, lengths=lengths)\n        elif self.args.model.lower() == \"gat\":\n            sent_out, graph_out = self.encoder(adj=adj, inputs=inputs, lengths=lengths)\n        elif self.args.model.lower() == \"rgat\":\n            sent_out, graph_out = self.encoder(adj=adj, relation_matrix=label_all, inputs=inputs, lengths=lengths)\n        elif self.args.model.lower() == \"rgat-noadj\":\n            sent_out, graph_out = self.encoder(adj=None, relation_matrix=label_all, inputs=inputs, lengths=lengths)\n        else:\n            print(f\"Invalid model name {self.args.model.lower()}, it should be (std, GAT, RGAT)\")\n            exit(0)\n\n        # ########### pooling and fusion #################\n        asp_wn = mask_ori.sum(dim=1).unsqueeze(-1)\n        mask = mask_ori.unsqueeze(-1).repeat(1, 1, self.args.hidden_dim)\n\n        if self.args.pooling.lower() == \"avg\":\n            graph_out = (graph_out * mask).sum(dim=1) / asp_wn\n        elif self.args.pooling.lower() == \"max\":\n            graph_out = torch.max(graph_out * mask, dim=1).values\n\n        if self.args.output_merge.lower() == \"none\":\n            return graph_out\n\n        sent_out = self.inp_map(sent_out)\n        if self.args.pooling.lower() == \"avg\":\n            sent_out = (sent_out * mask).sum(dim=1) / asp_wn\n        elif self.args.pooling.lower() == \"max\":\n            sent_out = torch.max(sent_out * mask, dim=1).values\n\n        if self.args.output_merge.lower() == \"gate\":\n            gate = torch.sigmoid(self.out_gate_map(torch.cat([graph_out, sent_out], dim=-1)))\n            outputs = graph_out * gate + (1 - gate) * sent_out\n        elif self.args.output_merge.lower() == \"gatenorm\":\n            gate = torch.sigmoid(self.out_gate_map(torch.cat([graph_out, sent_out], dim=-1)))\n            outputs = self.out_norm(graph_out * gate + (1 - gate) * sent_out)\n        elif self.args.output_merge.lower() == \"gatenorm2\":\n            gate = self.out_norm(torch.sigmoid(self.out_gate_map(torch.cat([graph_out, sent_out], dim=-1))))\n            outputs = graph_out * gate + (1 - gate) * sent_out\n        elif self.args.output_merge.lower() == \"addnorm\":\n            outputs = self.out_norm(graph_out + sent_out)\n        elif self.args.output_merge.lower() == \"add\":\n            outputs = graph_out + sent_out\n        elif self.args.output_merge.lower() == \"attn\":\n            att = torch.sigmoid(self.out_attn_map(torch.cat([graph_out, sent_out], dim=-1)))\n            outputs = graph_out * att + (1 - att) * sent_out\n\n        return outputs\n\n\nclass DoubleEncoder(nn.Module):\n    def __init__(self, args, embeddings, mem_dim, num_layers, use_dep=False):\n        super(DoubleEncoder, self).__init__()\n        self.args = args\n        self.layers = num_layers\n        self.mem_dim = mem_dim\n        self.in_dim = args.emb_dim + args.post_dim + args.pos_dim\n\n        if use_dep:\n            self.emb, self.pos_emb, self.post_emb, self.dep_emb = embeddings\n        else:\n            self.emb, self.pos_emb, self.post_emb = embeddings\n\n        input_size = self.in_dim\n        self.Sent_encoder = nn.LSTM(\n            input_size,\n            args.rnn_hidden,\n            args.rnn_layers,\n            batch_first=True,\n            dropout=args.rnn_dropout,\n            bidirectional=args.bidirect,\n        )\n        self.in_dim = args.rnn_hidden * 2 if args.bidirect else args.rnn_hidden\n\n        self.rnn_drop = nn.Dropout(args.rnn_dropout)\n        self.in_drop = nn.Dropout(args.input_dropout)\n\n        if use_dep:\n            self.graph_encoder = RGATEncoder(\n                num_layers=num_layers,\n                d_model=args.rnn_hidden * 2,\n                heads=args.attn_heads,\n                d_ff=args.rnn_hidden * 2,\n                dropout=args.layer_dropout,\n                att_drop=args.att_dropout,\n                use_structure=True,\n                alpha=args.alpha,\n                beta=args.beta,\n            )\n        else:\n            encoder_layer = nn.TransformerEncoderLayer(\n                d_model=args.rnn_hidden * 2,\n                nhead=args.attn_heads,\n                dim_feedforward=args.rnn_hidden * 2,\n                dropout=args.layer_dropout,\n            )\n            self.graph_encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=num_layers)\n\n        self.out_map = nn.Linear(args.rnn_hidden * 2, args.rnn_hidden)\n\n    def encode_with_rnn(self, rnn_inputs, seq_lens, batch_size):\n        h0, c0 = rnn_zero_state(batch_size, self.args.rnn_hidden, self.args.rnn_layers, self.args.bidirect)\n        rnn_inputs = nn.utils.rnn.pack_padded_sequence(rnn_inputs, seq_lens.cpu(), batch_first=True)\n        rnn_outputs, _ = self.Sent_encoder(rnn_inputs, (h0, c0))\n        rnn_outputs, _ = nn.utils.rnn.pad_packed_sequence(rnn_outputs, batch_first=True)\n        return rnn_outputs\n\n    def forward(self, adj, inputs, lengths, relation_matrix=None):\n        tok, asp, pos, head, deprel, post, a_mask, seq_len = inputs\n\n        word_embs = self.emb(tok)\n        embs = [word_embs]\n        if self.args.pos_dim > 0:\n            embs += [self.pos_emb(pos)]\n        if self.args.post_dim > 0:\n            embs += [self.post_emb(post)]\n        embs = torch.cat(embs, dim=2)\n        embs = self.in_drop(embs)\n\n        sent_output = self.rnn_drop(self.encode_with_rnn(embs, seq_len, tok.size(0)))\n\n        mask = adj.eq(0) if adj is not None else None\n        key_padding_mask = sequence_mask(lengths) if lengths is not None else None\n        dep_relation_embs = self.dep_emb(relation_matrix) if relation_matrix is not None else None\n\n        inp = sent_output.transpose(0, 1)\n        graph_output = self.graph_encoder(inp, mask=mask, src_key_padding_mask=key_padding_mask)\n        graph_output = graph_output.transpose(0, 1)\n        graph_output = self.out_map(graph_output)\n        return sent_output, graph_output\n\n\ndef rnn_zero_state(batch_size, hidden_dim, num_layers, bidirectional=True):\n    total_layers = num_layers * 2 if bidirectional else num_layers\n    state_shape = (total_layers, batch_size, hidden_dim)\n    h0 = c0 = Variable(torch.zeros(*state_shape), requires_grad=False)\n    return h0.cuda(), c0.cuda()\n\n\ndef sequence_mask(lengths, max_len=None):\n    batch_size = lengths.numel()\n    max_len = max_len or lengths.max()\n    return torch.arange(0, max_len, device=lengths.device).type_as(lengths).unsqueeze(0).expand(\n        batch_size, max_len\n    ) >= lengths.unsqueeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:35:22.222211Z","iopub.execute_input":"2025-06-01T08:35:22.222933Z","iopub.status.idle":"2025-06-01T08:35:22.254047Z","shell.execute_reply.started":"2025-06-01T08:35:22.222898Z","shell.execute_reply":"2025-06-01T08:35:22.253460Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport torch\n\n\nclass ABSADataLoader(object):\n    def __init__(self, filename, batch_size, args, vocab, shuffle=True):\n        self.batch_size = batch_size\n        self.args = args\n        self.vocab = vocab\n\n        assert os.path.exists(filename), filename\n        with open(filename, \"r\") as infile:\n            data = json.load(infile)\n        self.raw_data = data\n\n        # preprocess data\n        data = self.preprocess(data, vocab, args)\n\n        print(\"{} instances loaded from {}\".format(len(data), filename))\n\n        if shuffle:\n            indices = np.arange(len(data))\n            np.random.shuffle(indices)\n            data = [data[idx] for idx in indices]\n\n        # labels\n        pol_vocab = vocab[-1]\n        self.labels = [pol_vocab.itos[d[-1]] for d in data]\n\n        # example num\n        self.num_examples = len(data)\n\n        # chunk into batches\n        data = [data[i: i + batch_size] for i in range(0, len(data), batch_size)]\n        self.data = data\n        print(\"{} batches created for {}\".format(len(data), filename))\n\n    def preprocess(self, data, vocab, args):\n        # unpack vocab\n        token_vocab, post_vocab, pos_vocab, dep_vocab, pol_vocab = vocab\n        processed = []\n\n        for d in data:\n            for aspect in d[\"aspects\"]:\n                # word token\n                tok = list(d[\"token\"])\n                if args.lower:\n                    tok = [t.lower() for t in tok]\n\n                # aspect\n                asp = list(aspect[\"term\"])\n                # label\n                label = aspect[\"polarity\"]\n                # pos_tag\n                pos = list(d[\"pos\"])\n                # head\n                head = list(d[\"head\"])\n                # deprel\n                deprel = list(d[\"deprel\"])\n                # real length\n                length = len(tok)\n\n                # position\n                post = (\n                    [i - aspect[\"from\"] for i in range(aspect[\"from\"])]\n                    + [0 for _ in range(aspect[\"from\"], aspect[\"to\"])]\n                    + [i - aspect[\"to\"] + 1 for i in range(aspect[\"to\"], length)]\n                )\n\n                # aspect mask\n                if len(asp) == 0:\n                    mask = [1 for _ in range(length)]  # for rest16\n                else:\n                    mask = (\n                        [0 for _ in range(aspect[\"from\"])]\n                        + [1 for _ in range(aspect[\"from\"], aspect[\"to\"])]\n                        + [0 for _ in range(aspect[\"to\"], length)]\n                    )\n\n                # mapping token\n                tok = [token_vocab.stoi.get(t, token_vocab.unk_index) for t in tok]\n                # mapping aspect\n                asp = [token_vocab.stoi.get(t, token_vocab.unk_index) for t in asp]\n                # mapping label\n                label = pol_vocab.stoi.get(label)\n                # mapping pos\n                pos = [pos_vocab.stoi.get(t, pos_vocab.unk_index) for t in pos]\n                # mapping head to int\n                head = [int(x) for x in head]\n                assert any([x == 0 for x in head])\n                # mapping deprel\n                deprel = [dep_vocab.stoi.get(t, dep_vocab.unk_index) for t in deprel]\n                # mapping post\n                post = [post_vocab.stoi.get(t, post_vocab.unk_index) for t in post]\n\n                assert (\n                    len(tok) == length\n                    and len(pos) == length\n                    and len(head) == length\n                    and len(deprel) == length\n                    and len(post) == length\n                    and len(mask) == length\n                )\n\n                processed += [(tok, asp, pos, head, deprel, post, mask, length, label)]\n\n        return processed\n\n    def gold(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, key):\n        if not isinstance(key, int):\n            raise TypeError\n        if key < 0 or key >= len(self.data):\n            raise IndexError\n\n        batch = self.data[key]\n        batch_size = len(batch)\n        batch = list(zip(*batch))\n\n        # sort all fields by lens for easy RNN operations\n        lens = [len(x) for x in batch[0]]\n        batch, orig_idx = sort_all(batch, lens)\n\n        # convert to tensors\n        tok = get_long_tensor(batch[0], batch_size)\n        asp = get_long_tensor(batch[1], batch_size)\n        pos = get_long_tensor(batch[2], batch_size)\n        head = get_long_tensor(batch[3], batch_size)\n        deprel = get_long_tensor(batch[4], batch_size)\n        post = get_long_tensor(batch[5], batch_size)\n        mask = get_float_tensor(batch[6], batch_size)\n        length = torch.LongTensor(batch[7])\n        label = torch.LongTensor(batch[8])\n\n        return (tok, asp, pos, head, deprel, post, mask, length, label)\n\n    def __iter__(self):\n        for i in range(self.__len__()):\n            yield self.__getitem__(i)\n\n\ndef get_long_tensor(tokens_list, batch_size):\n    \"\"\"Convert list of list of tokens to a padded LongTensor.\"\"\"\n    token_len = max(len(x) for x in tokens_list)\n    tokens = torch.LongTensor(batch_size, token_len).fill_(0)\n    for i, s in enumerate(tokens_list):\n        tokens[i, :len(s)] = torch.LongTensor(s)\n    return tokens\n\n\ndef get_float_tensor(tokens_list, batch_size):\n    \"\"\"Convert list of list of tokens to a padded FloatTensor.\"\"\"\n    token_len = max(len(x) for x in tokens_list)\n    tokens = torch.FloatTensor(batch_size, token_len).fill_(0)\n    for i, s in enumerate(tokens_list):\n        tokens[i, :len(s)] = torch.FloatTensor(s)\n    return tokens\n\n\ndef sort_all(batch, lens):\n    \"\"\"Sort all fields by descending order of lens, and return the original indices.\"\"\"\n    unsorted_all = [lens] + [range(len(lens))] + list(batch)\n    sorted_all = [list(t) for t in zip(*sorted(zip(*unsorted_all), reverse=True))]\n    return sorted_all[2:], sorted_all[1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:37:51.844265Z","iopub.execute_input":"2025-06-01T08:37:51.844735Z","iopub.status.idle":"2025-06-01T08:37:51.861859Z","shell.execute_reply.started":"2025-06-01T08:37:51.844715Z","shell.execute_reply":"2025-06-01T08:37:51.861210Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"def load_pretrained_embedding(glove_dir, word_list, dimension_size=300, encoding=\"utf-8\"):\n    pre_words = []\n    count = 0\n\n    with open(glove_dir + \"/glove.840B.300d.txt\", \"r\", encoding=encoding) as fopen:\n        for line in fopen:\n            pre_words.append(line.strip())\n    word2offset = {w: i for i, w in enumerate(pre_words)}\n\n    word_vectors = []\n    for word in word_list:\n        if word in word2offset:\n            line = linecache.getline(glove_dir + \"/glove.840B.300d.txt\", word2offset[word] + 1)\n            assert word == line[: line.find(\" \")].strip()\n            word_vectors.append(\n                np.fromstring(line[line.find(\" \"):].strip(), sep=\" \", dtype=np.float32)\n            )\n            count += 1\n        else:\n            # init zero\n            word_vectors.append(np.zeros(dimension_size, dtype=np.float32))\n    print(\"Loading {}/{} words from vocab...\".format(count, len(word_list)))\n\n    return word_vectors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:38:12.135320Z","iopub.execute_input":"2025-06-01T08:38:12.135569Z","iopub.status.idle":"2025-06-01T08:38:12.141190Z","shell.execute_reply.started":"2025-06-01T08:38:12.135552Z","shell.execute_reply":"2025-06-01T08:38:12.140480Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"import os\nimport six\n\ndef ensure_dir(d, verbose=True):\n    if not os.path.exists(d):\n        if verbose:\n            print(\"Directory {} does not exist; creating...\".format(d))\n        os.makedirs(d)\n\n\nclass FileLogger(object):\n    \"\"\"\n    A file logger that opens the file periodically and writes to it.\n    \"\"\"\n    def __init__(self, filename, header=None):\n        self.filename = filename\n        if os.path.exists(filename):\n            # remove the old file\n            os.remove(filename)\n        if header is not None:\n            with open(filename, 'w') as out:\n                print(header, file=out)\n    \n    def log(self, message):\n        with open(self.filename, 'a') as out:\n            print(message, file=out)\n\n\ndef print_arguments(args):\n    print('-----------  Configuration Arguments -----------')\n    for arg, value in sorted(six.iteritems(vars(args))):\n        print('%s: %s' % (arg, value))\n    print('------------------------------------------------')\n\n\ndef unpack_raw_data(raw_data, batch_size=32):\n    unpacked = []\n    for d in raw_data: \n        for a in d['aspects']:\n            unpacked.append({'token': d['token'], 'aspect': a, 'polarity': a['polarity']})\n    \n    batches = [unpacked[i:i + batch_size] for i in range(0, len(unpacked), batch_size)]\n    \n    sorted_unpacked = []\n    for batch in batches:\n        lens = [len(x['token']) for x in batch]\n        temp = [t[0] for t in sorted(zip(batch, lens, range(len(lens))), key=lambda x: (x[1], x[2]), reverse=True)]\n        sorted_unpacked.extend(temp)\n    \n    return sorted_unpacked\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:39:32.100343Z","iopub.execute_input":"2025-06-01T08:39:32.100634Z","iopub.status.idle":"2025-06-01T08:39:32.109110Z","shell.execute_reply.started":"2025-06-01T08:39:32.100613Z","shell.execute_reply":"2025-06-01T08:39:32.108345Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Simulate argparse arguments for Jupyter Notebook\nargs = argparse.Namespace(\n    data_dir=\"/kaggle/input/laptop-dataset\",\n    vocab_dir=\"/kaggle/working/vocab/laptop-dataset\",\n    glove_dir=\"/kaggle/input/glovewordembeddings\",\n    emb_dim=300,\n    post_dim=30,\n    pos_dim=30,\n    dep_dim=30,\n    hidden_dim=50,\n    num_layers=2,\n    num_class=3,\n    cross_val_fold=10,\n    input_dropout=0.7,\n    layer_dropout=0,\n    att_dropout=0,\n    attn_heads=5,\n    alpha=1.0,\n    beta=1.0,\n    lower=True,\n    direct=False,\n    bidirect=True,\n    loop=True,\n    rnn_hidden=50,\n    rnn_layers=1,\n    rnn_dropout=0.1,\n    lr=0.01,\n    optim=\"adamax\",\n    num_epoch=100,\n    batch_size=32,\n    log_step=20,\n    log=\"logs.txt\",\n    save_dir=\"./saved_models\",\n     model=\"std\",\n    pooling=\"avg\",\n    output_merge=\"none\",\n    shuffle=False,\n    seed=0,\n    tune=False\n)\n\n# Now you can access the arguments through `args` object, e.g.:\nprint(args.data_dir)\nprint(args.emb_dim)\nprint(f\"Training file path: {args.data_dir + '/train.json'}\")\nprint(f\"Validation file path: {args.data_dir + '/valid.json'}\")\nprint(f\"Test file path: {args.data_dir + '/test.json'}\")\ndef get_dataloaders(args, vocab):\n    train_batch = ABSADataLoader(\n        args.data_dir + \"/valid.json\", args.batch_size, args, vocab, shuffle=args.shuffle\n    )\n    valid_batch = ABSADataLoader(\n        args.data_dir + \"/valid.json\", args.batch_size, args, vocab, shuffle=False\n    )\n    test_batch = ABSADataLoader(\n        args.data_dir + \"/test.json\", args.batch_size, args, vocab, shuffle=False\n    )\n    return train_batch, valid_batch, test_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:48:18.810473Z","iopub.execute_input":"2025-06-01T08:48:18.811270Z","iopub.status.idle":"2025-06-01T08:48:18.818037Z","shell.execute_reply.started":"2025-06-01T08:48:18.811244Z","shell.execute_reply":"2025-06-01T08:48:18.817301Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/laptop-dataset\n300\nTraining file path: /kaggle/input/laptop-dataset/train.json\nValidation file path: /kaggle/input/laptop-dataset/valid.json\nTest file path: /kaggle/input/laptop-dataset/test.json\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# load vocab\nprint(\"Loading vocab...\")\nvocab_dir=\"/kaggle/working/vocab/laptop-dataset\"\ntoken_vocab = Vocab.load_vocab(vocab_dir + \"/vocab_tok.vocab\")  # token\npost_vocab = Vocab.load_vocab(vocab_dir + \"/vocab_post.vocab\")  # position\npos_vocab = Vocab.load_vocab(vocab_dir + \"/vocab_pos.vocab\")  # POS\ndep_vocab = Vocab.load_vocab(vocab_dir + \"/vocab_dep.vocab\")  # deprel\npol_vocab = Vocab.load_vocab(vocab_dir + \"/vocab_pol.vocab\")  # polarity\nvocab = (token_vocab, post_vocab, pos_vocab, dep_vocab, pol_vocab)\nprint(\n    \"token_vocab: {}, post_vocab: {}, pos_vocab: {}, dep_vocab: {}, pol_vocab: {}\".format(\n        len(token_vocab), len(post_vocab), len(pos_vocab), len(dep_vocab), len(pol_vocab)\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:48:24.055928Z","iopub.execute_input":"2025-06-01T08:48:24.056360Z","iopub.status.idle":"2025-06-01T08:48:24.062907Z","shell.execute_reply.started":"2025-06-01T08:48:24.056338Z","shell.execute_reply":"2025-06-01T08:48:24.062322Z"}},"outputs":[{"name":"stdout","text":"Loading vocab...\nLoading vocab from: /kaggle/working/vocab/laptop-dataset/vocab_tok.vocab\nLoading vocab from: /kaggle/working/vocab/laptop-dataset/vocab_post.vocab\nLoading vocab from: /kaggle/working/vocab/laptop-dataset/vocab_pos.vocab\nLoading vocab from: /kaggle/working/vocab/laptop-dataset/vocab_dep.vocab\nLoading vocab from: /kaggle/working/vocab/laptop-dataset/vocab_pol.vocab\ntoken_vocab: 3525, post_vocab: 168, pos_vocab: 46, dep_vocab: 34, pol_vocab: 3\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"print(f\"Training file path: {args.data_dir + '/train.json'}\")\nprint(f\"Validation file path: {args.data_dir + '/valid.json'}\")\nprint(f\"Test file path: {args.data_dir + '/test.json'}\")\ndef get_dataloaders(args, vocab):\n    train_batch = ABSADataLoader(\n        args.data_dir + \"/valid.json\", args.batch_size, args, vocab, shuffle=args.shuffle\n    )\n    valid_batch = ABSADataLoader(\n        args.data_dir + \"/valid.json\", args.batch_size, args, vocab, shuffle=False\n    )\n    test_batch = ABSADataLoader(\n        args.data_dir + \"/test.json\", args.batch_size, args, vocab, shuffle=False\n    )\n    return train_batch, valid_batch, test_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:48:28.340309Z","iopub.execute_input":"2025-06-01T08:48:28.340850Z","iopub.status.idle":"2025-06-01T08:48:28.345009Z","shell.execute_reply.started":"2025-06-01T08:48:28.340828Z","shell.execute_reply":"2025-06-01T08:48:28.344316Z"}},"outputs":[{"name":"stdout","text":"Training file path: /kaggle/input/laptop-dataset/train.json\nValidation file path: /kaggle/input/laptop-dataset/valid.json\nTest file path: /kaggle/input/laptop-dataset/test.json\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"def evaluate(model, data_loader):\n    predictions, labels = [], []\n    val_loss, val_acc, val_step = 0.0, 0.0, 0\n    for i, batch in enumerate(data_loader):\n        loss, acc, pred, label, _, _ = model.predict(batch)\n        val_loss += loss\n        val_acc += acc\n        predictions += pred\n        labels += label\n        val_step += 1\n    # f1 score\n    f1_score = metrics.f1_score(labels, predictions, average=\"macro\")\n    return val_loss / val_step, val_acc / val_step, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:48:32.570733Z","iopub.execute_input":"2025-06-01T08:48:32.571298Z","iopub.status.idle":"2025-06-01T08:48:32.575281Z","shell.execute_reply.started":"2025-06-01T08:48:32.571275Z","shell.execute_reply":"2025-06-01T08:48:32.574594Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"def _totally_parameters(model):  #\n    n_params = sum([p.nelement() for p in model.parameters()])\n    return n_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:48:37.430318Z","iopub.execute_input":"2025-06-01T08:48:37.430841Z","iopub.status.idle":"2025-06-01T08:48:37.434344Z","shell.execute_reply.started":"2025-06-01T08:48:37.430820Z","shell.execute_reply":"2025-06-01T08:48:37.433620Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# train model\ndef trainmodel(config=None):\n    if config is not None:\n        args.batch_size = config[\"bsz\"]\n        args.seed = config[\"npseed\"]\n        args.npseed = config[\"npseed\"]\n        args.input_dropout = config[\"inp_drop\"]\n\n    torch.manual_seed(args.seed)\n    np.random.seed(args.seed)\n    random.seed(args.seed)\n    torch.cuda.manual_seed(args.seed)\n\n    print_arguments(args)\n\n    train_batch, valid_batch, test_batch = get_dataloaders(args, vocab)\n\n    trainer = ABSATrainer(args, emb_matrix=word_emb)\n    print(trainer.model)\n    print(\"Total parameters:\", _totally_parameters(trainer.model))\n\n    best_path = args.save_dir\n    ensure_dir(best_path, verbose=True)\n\n    print(\"Training Set: {}\".format(len(train_batch)))\n    print(\"Valid Set: {}\".format(len(valid_batch)))\n    print(\"Test Set: {}\".format(len(test_batch)))\n\n    train_acc_history, train_loss_history = [], []\n    val_acc_history, val_loss_history, val_f1_score_history = [0.0], [0.0], [0.0]\n    patience = 0\n    epoch = 0\n\n    for _ in range(1, args.num_epoch + 1):\n        epoch += 1\n        print(\"Epoch {}\".format(epoch) + \"-\" * 60)\n        train_loss, train_acc, train_step = 0.0, 0.0, 0\n\n        for i, batch in enumerate(train_batch):\n            loss, acc = trainer.update(batch)\n            train_loss += loss\n            train_acc += acc\n            train_step += 1\n\n            if train_step % args.log_step == 0:\n                print(\n                    \"{}/{} train_loss: {:.6f}, train_acc: {:.6f}\".format(\n                        i, len(train_batch), train_loss / train_step, train_acc / train_step\n                    )\n                )\n\n        val_loss, val_acc, val_f1 = evaluate(trainer, valid_batch)\n\n        print(\n            \"End of {} train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, f1_score: {:.4f}\".format(\n                epoch,\n                train_loss / train_step,\n                train_acc / train_step,\n                val_loss,\n                val_acc,\n                val_f1,\n            )\n        )\n\n        train_acc_history.append(train_acc / train_step)\n        train_loss_history.append(train_loss / train_step)\n        val_loss_history.append(val_loss)\n\n        # save best model\n        if epoch == 1 or float(val_acc) > max(val_acc_history):\n            patience = 0\n            torch.save(trainer, best_path + '/best_checkpoint.pt')\n            print(\"new best model saved.\")\n        else:\n            patience += 1\n\n        val_acc_history.append(float(val_acc))\n        val_f1_score_history.append(val_f1)\n\n        if patience >= 20:\n            print('Reach the max patience, stopping...')\n            break\n\n    print(\"Training ended with {} epochs.\".format(epoch))\n\n    print(\"Loading best checkpoints from\", best_path + '/best_checkpoint.pt')\n    # trainer = torch.load(best_path + '/best_checkpoint.pt')\n    trainer = torch.load(best_path + '/best_checkpoint.pt', weights_only=False)\n    test_loss, test_acc, test_f1 = evaluate(trainer, test_batch)\n    print(\"Evaluation Results: test_loss:{}, test_acc:{}, test_f1:{}\".format(test_loss, test_acc, test_f1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:57:13.410975Z","iopub.execute_input":"2025-06-01T08:57:13.411516Z","iopub.status.idle":"2025-06-01T08:57:13.421515Z","shell.execute_reply.started":"2025-06-01T08:57:13.411486Z","shell.execute_reply":"2025-06-01T08:57:13.420800Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"args.tok_size = len(token_vocab)\nargs.post_size = len(post_vocab)\nargs.pos_size = len(pos_vocab)\nargs.dep_size = len(dep_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:57:18.810320Z","iopub.execute_input":"2025-06-01T08:57:18.810591Z","iopub.status.idle":"2025-06-01T08:57:18.814278Z","shell.execute_reply.started":"2025-06-01T08:57:18.810571Z","shell.execute_reply":"2025-06-01T08:57:18.813675Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"import os\nimport json\nimport six\nimport argparse\nimport subprocess\n\ndef ensure_dir(d, verbose=True):\n    if not os.path.exists(d):\n        if verbose:\n            print(\"Directory {} do not exist; creating...\".format(d))\n        os.makedirs(d)\n\nclass FileLogger(object):\n    \"\"\"\n    A file logger that opens the file periodically and writes to it.\n    \"\"\"\n    def __init__(self, filename, header=None):\n        self.filename = filename\n        if os.path.exists(filename):\n            # remove the old file\n            os.remove(filename)\n        if header is not None:\n            with open(filename, 'w') as out:\n                print(header, file=out)\n    \n    def log(self, message):\n        with open(self.filename, 'a') as out:\n            print(message, file=out)\n\ndef print_arguments(args):\n    print('-----------  Configuration Arguments -----------')\n    for arg, value in sorted(six.iteritems(vars(args))):\n        print('%s: %s' % (arg, value))\n    print('------------------------------------------------')\n\ndef unpack_raw_data(raw_data, batch_size=32):\n    unpacked = []\n    for d in raw_data: \n        for a in d['aspects']:\n            unpacked.append({'token': d['token'], 'aspect': a, 'polarity': a['polarity']})\n    \n    batches = [unpacked[i:i+batch_size] for i in range(0, len(unpacked), batch_size)]\n    \n    unpacked = []\n    for batch in batches:\n        lens = [len(x['token']) for x in batch]\n        temp = [t[0] for t in list(sorted(zip(batch, lens, list(range(len(lens)))), key=lambda x: (x[1], x[2]), reverse=True))]\n        unpacked.extend(temp)\n    \n    return unpacked\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:57:22.585434Z","iopub.execute_input":"2025-06-01T08:57:22.585832Z","iopub.status.idle":"2025-06-01T08:57:22.593837Z","shell.execute_reply.started":"2025-06-01T08:57:22.585810Z","shell.execute_reply":"2025-06-01T08:57:22.593298Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"# load pretrained word emb\nprint(\"Loading pretrained word emb...\")\nword_emb = load_pretrained_embedding(glove_dir=\"/kaggle/input/glovewordembeddings\", word_list=token_vocab.itos)\nassert len(word_emb) == len(token_vocab)\nassert len(word_emb[0]) == args.emb_dim\nword_emb = torch.FloatTensor(word_emb)  # convert to tensor\n\n\nif __name__ == \"__main__\":\n    trainmodel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:57:26.970432Z","iopub.execute_input":"2025-06-01T08:57:26.970951Z","iopub.status.idle":"2025-06-01T09:01:26.172546Z","shell.execute_reply.started":"2025-06-01T08:57:26.970929Z","shell.execute_reply":"2025-06-01T09:01:26.171838Z"}},"outputs":[{"name":"stdout","text":"Loading pretrained word emb...\nLoading 0/3525 words from vocab...\n-----------  Configuration Arguments -----------\nalpha: 1.0\natt_dropout: 0\nattn_heads: 5\nbatch_size: 32\nbeta: 1.0\nbidirect: True\ncross_val_fold: 10\ndata_dir: /kaggle/input/laptop-dataset\ndep_dim: 30\ndep_size: 34\ndirect: False\nemb_dim: 300\nglove_dir: /kaggle/input/glovewordembeddings\nhidden_dim: 50\ninput_dropout: 0.7\nlayer_dropout: 0\nlog: logs.txt\nlog_step: 20\nloop: True\nlower: True\nlr: 0.01\nmodel: std\nnum_class: 3\nnum_epoch: 100\nnum_layers: 2\noptim: adamax\noutput_merge: none\npooling: avg\npos_dim: 30\npos_size: 46\npost_dim: 30\npost_size: 168\nrnn_dropout: 0.1\nrnn_hidden: 50\nrnn_layers: 1\nsave_dir: ./saved_models\nseed: 0\nshuffle: False\ntok_size: 3525\ntune: False\nvocab_dir: /kaggle/working/vocab/laptop-dataset\n------------------------------------------------\n632 instances loaded from /kaggle/input/laptop-dataset/valid.json\n20 batches created for /kaggle/input/laptop-dataset/valid.json\n632 instances loaded from /kaggle/input/laptop-dataset/valid.json\n20 batches created for /kaggle/input/laptop-dataset/valid.json\n632 instances loaded from /kaggle/input/laptop-dataset/test.json\n20 batches created for /kaggle/input/laptop-dataset/test.json\nRGATABSA(\n  (enc): ABSAEncoder(\n    (emb): Embedding(3525, 300, padding_idx=0)\n    (pos_emb): Embedding(46, 30, padding_idx=0)\n    (post_emb): Embedding(168, 30, padding_idx=0)\n    (encoder): DoubleEncoder(\n      (emb): Embedding(3525, 300, padding_idx=0)\n      (pos_emb): Embedding(46, 30, padding_idx=0)\n      (post_emb): Embedding(168, 30, padding_idx=0)\n      (Sent_encoder): LSTM(360, 50, batch_first=True, dropout=0.1, bidirectional=True)\n      (rnn_drop): Dropout(p=0.1, inplace=False)\n      (in_drop): Dropout(p=0.7, inplace=False)\n      (graph_encoder): TransformerEncoder(\n        (layers): ModuleList(\n          (0-1): 2 x TransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n            )\n            (linear1): Linear(in_features=100, out_features=100, bias=True)\n            (dropout): Dropout(p=0, inplace=False)\n            (linear2): Linear(in_features=100, out_features=100, bias=True)\n            (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0, inplace=False)\n            (dropout2): Dropout(p=0, inplace=False)\n          )\n        )\n      )\n      (out_map): Linear(in_features=100, out_features=50, bias=True)\n    )\n  )\n  (classifier): Linear(in_features=50, out_features=3, bias=True)\n)\nTotal parameters: 1355923\nTraining Set: 20\nValid Set: 20\nTest Set: 20\nEpoch 1------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"19/20 train_loss: 1.278596, train_acc: 43.437500\nEnd of 1 train_loss: 1.2786, train_acc: 43.4375, val_loss: 1.2468, val_acc: 26.5625, f1_score: 0.1393\nnew best model saved.\nEpoch 2------------------------------------------------------------\n19/20 train_loss: 1.154354, train_acc: 45.468750\nEnd of 2 train_loss: 1.1544, train_acc: 45.4688, val_loss: 1.1633, val_acc: 26.5625, f1_score: 0.1393\nEpoch 3------------------------------------------------------------\n19/20 train_loss: 1.110446, train_acc: 37.968750\nEnd of 3 train_loss: 1.1104, train_acc: 37.9688, val_loss: 1.0206, val_acc: 53.2812, f1_score: 0.2319\nnew best model saved.\nEpoch 4------------------------------------------------------------\n19/20 train_loss: 1.024956, train_acc: 53.281250\nEnd of 4 train_loss: 1.0250, train_acc: 53.2812, val_loss: 1.0131, val_acc: 53.2812, f1_score: 0.2319\nEpoch 5------------------------------------------------------------\n19/20 train_loss: 1.025551, train_acc: 53.281250\nEnd of 5 train_loss: 1.0256, train_acc: 53.2812, val_loss: 1.0102, val_acc: 53.2812, f1_score: 0.2319\nEpoch 6------------------------------------------------------------\n19/20 train_loss: 1.019327, train_acc: 53.281250\nEnd of 6 train_loss: 1.0193, train_acc: 53.2812, val_loss: 1.0096, val_acc: 53.2812, f1_score: 0.2319\nEpoch 7------------------------------------------------------------\n19/20 train_loss: 1.017524, train_acc: 53.281250\nEnd of 7 train_loss: 1.0175, train_acc: 53.2812, val_loss: 1.0087, val_acc: 53.2812, f1_score: 0.2319\nEpoch 8------------------------------------------------------------\n19/20 train_loss: 1.016722, train_acc: 53.281250\nEnd of 8 train_loss: 1.0167, train_acc: 53.2812, val_loss: 1.0066, val_acc: 53.2812, f1_score: 0.2319\nEpoch 9------------------------------------------------------------\n19/20 train_loss: 1.015045, train_acc: 53.281250\nEnd of 9 train_loss: 1.0150, train_acc: 53.2812, val_loss: 1.0009, val_acc: 53.2812, f1_score: 0.2319\nEpoch 10------------------------------------------------------------\n19/20 train_loss: 1.006191, train_acc: 53.281250\nEnd of 10 train_loss: 1.0062, train_acc: 53.2812, val_loss: 0.9763, val_acc: 53.1250, f1_score: 0.2801\nEpoch 11------------------------------------------------------------\n19/20 train_loss: 0.998592, train_acc: 51.562500\nEnd of 11 train_loss: 0.9986, train_acc: 51.5625, val_loss: 0.9737, val_acc: 53.2812, f1_score: 0.2319\nEpoch 12------------------------------------------------------------\n19/20 train_loss: 0.991198, train_acc: 53.489583\nEnd of 12 train_loss: 0.9912, train_acc: 53.4896, val_loss: 0.9675, val_acc: 52.3438, f1_score: 0.3705\nEpoch 13------------------------------------------------------------\n19/20 train_loss: 0.964723, train_acc: 52.083333\nEnd of 13 train_loss: 0.9647, train_acc: 52.0833, val_loss: 0.9610, val_acc: 53.8021, f1_score: 0.3980\nnew best model saved.\nEpoch 14------------------------------------------------------------\n19/20 train_loss: 0.976683, train_acc: 51.718750\nEnd of 14 train_loss: 0.9767, train_acc: 51.7188, val_loss: 0.9681, val_acc: 55.9375, f1_score: 0.4104\nnew best model saved.\nEpoch 15------------------------------------------------------------\n19/20 train_loss: 0.968825, train_acc: 52.500000\nEnd of 15 train_loss: 0.9688, train_acc: 52.5000, val_loss: 0.9570, val_acc: 53.0729, f1_score: 0.3934\nEpoch 16------------------------------------------------------------\n19/20 train_loss: 0.973081, train_acc: 51.302083\nEnd of 16 train_loss: 0.9731, train_acc: 51.3021, val_loss: 0.9059, val_acc: 60.3646, f1_score: 0.4344\nnew best model saved.\nEpoch 17------------------------------------------------------------\n19/20 train_loss: 0.930940, train_acc: 54.322917\nEnd of 17 train_loss: 0.9309, train_acc: 54.3229, val_loss: 0.8741, val_acc: 59.1146, f1_score: 0.4324\nEpoch 18------------------------------------------------------------\n19/20 train_loss: 0.911177, train_acc: 55.312500\nEnd of 18 train_loss: 0.9112, train_acc: 55.3125, val_loss: 0.8417, val_acc: 60.5208, f1_score: 0.4415\nnew best model saved.\nEpoch 19------------------------------------------------------------\n19/20 train_loss: 0.911264, train_acc: 57.343750\nEnd of 19 train_loss: 0.9113, train_acc: 57.3438, val_loss: 0.8549, val_acc: 61.5104, f1_score: 0.4474\nnew best model saved.\nEpoch 20------------------------------------------------------------\n19/20 train_loss: 0.904726, train_acc: 59.270833\nEnd of 20 train_loss: 0.9047, train_acc: 59.2708, val_loss: 0.9080, val_acc: 56.5104, f1_score: 0.4172\nEpoch 21------------------------------------------------------------\n19/20 train_loss: 0.920977, train_acc: 55.572917\nEnd of 21 train_loss: 0.9210, train_acc: 55.5729, val_loss: 0.8383, val_acc: 59.2708, f1_score: 0.4344\nEpoch 22------------------------------------------------------------\n19/20 train_loss: 0.881668, train_acc: 59.687500\nEnd of 22 train_loss: 0.8817, train_acc: 59.6875, val_loss: 0.8512, val_acc: 59.8958, f1_score: 0.4386\nEpoch 23------------------------------------------------------------\n19/20 train_loss: 0.902493, train_acc: 58.385417\nEnd of 23 train_loss: 0.9025, train_acc: 58.3854, val_loss: 0.8619, val_acc: 58.4896, f1_score: 0.4303\nEpoch 24------------------------------------------------------------\n19/20 train_loss: 0.896562, train_acc: 59.270833\nEnd of 24 train_loss: 0.8966, train_acc: 59.2708, val_loss: 0.8573, val_acc: 59.2708, f1_score: 0.4653\nEpoch 25------------------------------------------------------------\n19/20 train_loss: 0.908108, train_acc: 55.416667\nEnd of 25 train_loss: 0.9081, train_acc: 55.4167, val_loss: 0.7992, val_acc: 63.8021, f1_score: 0.5247\nnew best model saved.\nEpoch 26------------------------------------------------------------\n19/20 train_loss: 0.845528, train_acc: 62.447917\nEnd of 26 train_loss: 0.8455, train_acc: 62.4479, val_loss: 0.8302, val_acc: 60.8333, f1_score: 0.4722\nEpoch 27------------------------------------------------------------\n19/20 train_loss: 0.900173, train_acc: 55.833333\nEnd of 27 train_loss: 0.9002, train_acc: 55.8333, val_loss: 0.8241, val_acc: 64.3229, f1_score: 0.5521\nnew best model saved.\nEpoch 28------------------------------------------------------------\n19/20 train_loss: 0.863941, train_acc: 59.114583\nEnd of 28 train_loss: 0.8639, train_acc: 59.1146, val_loss: 0.7597, val_acc: 65.9375, f1_score: 0.5634\nnew best model saved.\nEpoch 29------------------------------------------------------------\n19/20 train_loss: 0.818876, train_acc: 61.979167\nEnd of 29 train_loss: 0.8189, train_acc: 61.9792, val_loss: 0.7596, val_acc: 65.7292, f1_score: 0.5499\nEpoch 30------------------------------------------------------------\n19/20 train_loss: 0.852406, train_acc: 59.739583\nEnd of 30 train_loss: 0.8524, train_acc: 59.7396, val_loss: 0.7626, val_acc: 69.5312, f1_score: 0.5935\nnew best model saved.\nEpoch 31------------------------------------------------------------\n19/20 train_loss: 0.836603, train_acc: 62.083333\nEnd of 31 train_loss: 0.8366, train_acc: 62.0833, val_loss: 0.7226, val_acc: 70.1562, f1_score: 0.6233\nnew best model saved.\nEpoch 32------------------------------------------------------------\n19/20 train_loss: 0.836718, train_acc: 62.500000\nEnd of 32 train_loss: 0.8367, train_acc: 62.5000, val_loss: 0.7446, val_acc: 66.5104, f1_score: 0.5508\nEpoch 33------------------------------------------------------------\n19/20 train_loss: 0.818204, train_acc: 64.427083\nEnd of 33 train_loss: 0.8182, train_acc: 64.4271, val_loss: 0.7267, val_acc: 69.3229, f1_score: 0.5971\nEpoch 34------------------------------------------------------------\n19/20 train_loss: 0.807080, train_acc: 64.166667\nEnd of 34 train_loss: 0.8071, train_acc: 64.1667, val_loss: 0.7225, val_acc: 66.3542, f1_score: 0.5654\nEpoch 35------------------------------------------------------------\n19/20 train_loss: 0.803781, train_acc: 63.333333\nEnd of 35 train_loss: 0.8038, train_acc: 63.3333, val_loss: 0.6874, val_acc: 70.4688, f1_score: 0.6234\nnew best model saved.\nEpoch 36------------------------------------------------------------\n19/20 train_loss: 0.805965, train_acc: 65.260417\nEnd of 36 train_loss: 0.8060, train_acc: 65.2604, val_loss: 0.7099, val_acc: 70.0000, f1_score: 0.5730\nEpoch 37------------------------------------------------------------\n19/20 train_loss: 0.796156, train_acc: 66.927083\nEnd of 37 train_loss: 0.7962, train_acc: 66.9271, val_loss: 0.6832, val_acc: 73.5417, f1_score: 0.6552\nnew best model saved.\nEpoch 38------------------------------------------------------------\n19/20 train_loss: 0.808376, train_acc: 63.750000\nEnd of 38 train_loss: 0.8084, train_acc: 63.7500, val_loss: 0.6960, val_acc: 70.6250, f1_score: 0.6411\nEpoch 39------------------------------------------------------------\n19/20 train_loss: 0.791469, train_acc: 65.052083\nEnd of 39 train_loss: 0.7915, train_acc: 65.0521, val_loss: 0.6803, val_acc: 71.1979, f1_score: 0.5796\nEpoch 40------------------------------------------------------------\n19/20 train_loss: 0.777659, train_acc: 64.687500\nEnd of 40 train_loss: 0.7777, train_acc: 64.6875, val_loss: 0.6461, val_acc: 72.8125, f1_score: 0.6464\nEpoch 41------------------------------------------------------------\n19/20 train_loss: 0.780581, train_acc: 64.895833\nEnd of 41 train_loss: 0.7806, train_acc: 64.8958, val_loss: 0.6373, val_acc: 74.6875, f1_score: 0.6706\nnew best model saved.\nEpoch 42------------------------------------------------------------\n19/20 train_loss: 0.770633, train_acc: 66.041667\nEnd of 42 train_loss: 0.7706, train_acc: 66.0417, val_loss: 0.6240, val_acc: 73.6979, f1_score: 0.6456\nEpoch 43------------------------------------------------------------\n19/20 train_loss: 0.778036, train_acc: 65.104167\nEnd of 43 train_loss: 0.7780, train_acc: 65.1042, val_loss: 0.6406, val_acc: 74.8958, f1_score: 0.6519\nnew best model saved.\nEpoch 44------------------------------------------------------------\n19/20 train_loss: 0.791926, train_acc: 64.687500\nEnd of 44 train_loss: 0.7919, train_acc: 64.6875, val_loss: 0.6852, val_acc: 70.0000, f1_score: 0.6394\nEpoch 45------------------------------------------------------------\n19/20 train_loss: 0.828555, train_acc: 61.354167\nEnd of 45 train_loss: 0.8286, train_acc: 61.3542, val_loss: 0.6326, val_acc: 73.4896, f1_score: 0.6499\nEpoch 46------------------------------------------------------------\n19/20 train_loss: 0.762142, train_acc: 65.729167\nEnd of 46 train_loss: 0.7621, train_acc: 65.7292, val_loss: 0.5663, val_acc: 77.7604, f1_score: 0.7181\nnew best model saved.\nEpoch 47------------------------------------------------------------\n19/20 train_loss: 0.751651, train_acc: 67.760417\nEnd of 47 train_loss: 0.7517, train_acc: 67.7604, val_loss: 0.6145, val_acc: 75.1562, f1_score: 0.6805\nEpoch 48------------------------------------------------------------\n19/20 train_loss: 0.762727, train_acc: 66.875000\nEnd of 48 train_loss: 0.7627, train_acc: 66.8750, val_loss: 0.5977, val_acc: 75.3125, f1_score: 0.6688\nEpoch 49------------------------------------------------------------\n19/20 train_loss: 0.723320, train_acc: 67.968750\nEnd of 49 train_loss: 0.7233, train_acc: 67.9688, val_loss: 0.5626, val_acc: 76.7708, f1_score: 0.7134\nEpoch 50------------------------------------------------------------\n19/20 train_loss: 0.777149, train_acc: 64.947917\nEnd of 50 train_loss: 0.7771, train_acc: 64.9479, val_loss: 0.6706, val_acc: 68.5417, f1_score: 0.6066\nEpoch 51------------------------------------------------------------\n19/20 train_loss: 0.787455, train_acc: 64.427083\nEnd of 51 train_loss: 0.7875, train_acc: 64.4271, val_loss: 0.5803, val_acc: 76.1979, f1_score: 0.6839\nEpoch 52------------------------------------------------------------\n19/20 train_loss: 0.691161, train_acc: 69.427083\nEnd of 52 train_loss: 0.6912, train_acc: 69.4271, val_loss: 0.5075, val_acc: 79.9479, f1_score: 0.7479\nnew best model saved.\nEpoch 53------------------------------------------------------------\n19/20 train_loss: 0.670269, train_acc: 71.197917\nEnd of 53 train_loss: 0.6703, train_acc: 71.1979, val_loss: 0.5907, val_acc: 74.8438, f1_score: 0.6771\nEpoch 54------------------------------------------------------------\n19/20 train_loss: 0.755127, train_acc: 66.666667\nEnd of 54 train_loss: 0.7551, train_acc: 66.6667, val_loss: 0.6233, val_acc: 75.0521, f1_score: 0.6797\nEpoch 55------------------------------------------------------------\n19/20 train_loss: 0.753253, train_acc: 65.885417\nEnd of 55 train_loss: 0.7533, train_acc: 65.8854, val_loss: 0.5353, val_acc: 80.7812, f1_score: 0.7615\nnew best model saved.\nEpoch 56------------------------------------------------------------\n19/20 train_loss: 0.703474, train_acc: 69.062500\nEnd of 56 train_loss: 0.7035, train_acc: 69.0625, val_loss: 0.5078, val_acc: 77.9167, f1_score: 0.7118\nEpoch 57------------------------------------------------------------\n19/20 train_loss: 0.718908, train_acc: 67.135417\nEnd of 57 train_loss: 0.7189, train_acc: 67.1354, val_loss: 0.5682, val_acc: 74.8958, f1_score: 0.6540\nEpoch 58------------------------------------------------------------\n19/20 train_loss: 0.688472, train_acc: 69.531250\nEnd of 58 train_loss: 0.6885, train_acc: 69.5312, val_loss: 0.4636, val_acc: 82.0833, f1_score: 0.7781\nnew best model saved.\nEpoch 59------------------------------------------------------------\n19/20 train_loss: 0.688425, train_acc: 69.739583\nEnd of 59 train_loss: 0.6884, train_acc: 69.7396, val_loss: 0.5220, val_acc: 78.3333, f1_score: 0.7329\nEpoch 60------------------------------------------------------------\n19/20 train_loss: 0.682536, train_acc: 68.593750\nEnd of 60 train_loss: 0.6825, train_acc: 68.5938, val_loss: 0.4675, val_acc: 82.2917, f1_score: 0.7890\nnew best model saved.\nEpoch 61------------------------------------------------------------\n19/20 train_loss: 0.683429, train_acc: 71.510417\nEnd of 61 train_loss: 0.6834, train_acc: 71.5104, val_loss: 0.4963, val_acc: 81.5625, f1_score: 0.7778\nEpoch 62------------------------------------------------------------\n19/20 train_loss: 0.667965, train_acc: 70.729167\nEnd of 62 train_loss: 0.6680, train_acc: 70.7292, val_loss: 0.4378, val_acc: 81.3021, f1_score: 0.7556\nEpoch 63------------------------------------------------------------\n19/20 train_loss: 0.656909, train_acc: 71.927083\nEnd of 63 train_loss: 0.6569, train_acc: 71.9271, val_loss: 0.4839, val_acc: 80.1562, f1_score: 0.7599\nEpoch 64------------------------------------------------------------\n19/20 train_loss: 0.651816, train_acc: 71.770833\nEnd of 64 train_loss: 0.6518, train_acc: 71.7708, val_loss: 0.4532, val_acc: 81.0938, f1_score: 0.7641\nEpoch 65------------------------------------------------------------\n19/20 train_loss: 0.654759, train_acc: 69.479167\nEnd of 65 train_loss: 0.6548, train_acc: 69.4792, val_loss: 0.4779, val_acc: 80.0521, f1_score: 0.7281\nEpoch 66------------------------------------------------------------\n19/20 train_loss: 0.681714, train_acc: 69.531250\nEnd of 66 train_loss: 0.6817, train_acc: 69.5312, val_loss: 0.4345, val_acc: 84.0104, f1_score: 0.7971\nnew best model saved.\nEpoch 67------------------------------------------------------------\n19/20 train_loss: 0.635447, train_acc: 74.739583\nEnd of 67 train_loss: 0.6354, train_acc: 74.7396, val_loss: 0.4100, val_acc: 83.9062, f1_score: 0.8043\nEpoch 68------------------------------------------------------------\n19/20 train_loss: 0.671800, train_acc: 72.291667\nEnd of 68 train_loss: 0.6718, train_acc: 72.2917, val_loss: 0.4728, val_acc: 81.2500, f1_score: 0.7832\nEpoch 69------------------------------------------------------------\n19/20 train_loss: 0.599006, train_acc: 75.833333\nEnd of 69 train_loss: 0.5990, train_acc: 75.8333, val_loss: 0.4134, val_acc: 82.3958, f1_score: 0.7854\nEpoch 70------------------------------------------------------------\n19/20 train_loss: 0.646081, train_acc: 74.270833\nEnd of 70 train_loss: 0.6461, train_acc: 74.2708, val_loss: 0.4510, val_acc: 80.3646, f1_score: 0.7529\nEpoch 71------------------------------------------------------------\n19/20 train_loss: 0.669847, train_acc: 70.260417\nEnd of 71 train_loss: 0.6698, train_acc: 70.2604, val_loss: 0.4291, val_acc: 83.5938, f1_score: 0.8058\nEpoch 72------------------------------------------------------------\n19/20 train_loss: 0.607299, train_acc: 74.322917\nEnd of 72 train_loss: 0.6073, train_acc: 74.3229, val_loss: 0.4689, val_acc: 80.5208, f1_score: 0.7438\nEpoch 73------------------------------------------------------------\n19/20 train_loss: 0.621998, train_acc: 69.427083\nEnd of 73 train_loss: 0.6220, train_acc: 69.4271, val_loss: 0.4178, val_acc: 82.3438, f1_score: 0.7521\nEpoch 74------------------------------------------------------------\n19/20 train_loss: 0.596614, train_acc: 74.583333\nEnd of 74 train_loss: 0.5966, train_acc: 74.5833, val_loss: 0.3647, val_acc: 86.7188, f1_score: 0.8344\nnew best model saved.\nEpoch 75------------------------------------------------------------\n19/20 train_loss: 0.575833, train_acc: 77.031250\nEnd of 75 train_loss: 0.5758, train_acc: 77.0312, val_loss: 0.3667, val_acc: 83.6979, f1_score: 0.7972\nEpoch 76------------------------------------------------------------\n19/20 train_loss: 0.616965, train_acc: 73.645833\nEnd of 76 train_loss: 0.6170, train_acc: 73.6458, val_loss: 0.3667, val_acc: 87.5000, f1_score: 0.8436\nnew best model saved.\nEpoch 77------------------------------------------------------------\n19/20 train_loss: 0.612900, train_acc: 75.937500\nEnd of 77 train_loss: 0.6129, train_acc: 75.9375, val_loss: 0.3479, val_acc: 89.0625, f1_score: 0.8657\nnew best model saved.\nEpoch 78------------------------------------------------------------\n19/20 train_loss: 0.613935, train_acc: 73.854167\nEnd of 78 train_loss: 0.6139, train_acc: 73.8542, val_loss: 0.3388, val_acc: 88.2812, f1_score: 0.8578\nEpoch 79------------------------------------------------------------\n19/20 train_loss: 0.581469, train_acc: 74.947917\nEnd of 79 train_loss: 0.5815, train_acc: 74.9479, val_loss: 0.3366, val_acc: 88.1250, f1_score: 0.8513\nEpoch 80------------------------------------------------------------\n19/20 train_loss: 0.597727, train_acc: 73.802083\nEnd of 80 train_loss: 0.5977, train_acc: 73.8021, val_loss: 0.3947, val_acc: 85.0000, f1_score: 0.8161\nEpoch 81------------------------------------------------------------\n19/20 train_loss: 0.636330, train_acc: 70.989583\nEnd of 81 train_loss: 0.6363, train_acc: 70.9896, val_loss: 0.3523, val_acc: 86.7188, f1_score: 0.8504\nEpoch 82------------------------------------------------------------\n19/20 train_loss: 0.591617, train_acc: 75.208333\nEnd of 82 train_loss: 0.5916, train_acc: 75.2083, val_loss: 0.2952, val_acc: 88.1250, f1_score: 0.8619\nEpoch 83------------------------------------------------------------\n19/20 train_loss: 0.574944, train_acc: 78.177083\nEnd of 83 train_loss: 0.5749, train_acc: 78.1771, val_loss: 0.3243, val_acc: 89.5312, f1_score: 0.8641\nnew best model saved.\nEpoch 84------------------------------------------------------------\n19/20 train_loss: 0.589786, train_acc: 74.947917\nEnd of 84 train_loss: 0.5898, train_acc: 74.9479, val_loss: 0.3252, val_acc: 90.3125, f1_score: 0.8781\nnew best model saved.\nEpoch 85------------------------------------------------------------\n19/20 train_loss: 0.547543, train_acc: 75.364583\nEnd of 85 train_loss: 0.5475, train_acc: 75.3646, val_loss: 0.3447, val_acc: 85.4688, f1_score: 0.8271\nEpoch 86------------------------------------------------------------\n19/20 train_loss: 0.581405, train_acc: 75.625000\nEnd of 86 train_loss: 0.5814, train_acc: 75.6250, val_loss: 0.3410, val_acc: 85.7812, f1_score: 0.8430\nEpoch 87------------------------------------------------------------\n19/20 train_loss: 0.568201, train_acc: 76.458333\nEnd of 87 train_loss: 0.5682, train_acc: 76.4583, val_loss: 0.3284, val_acc: 88.1250, f1_score: 0.8464\nEpoch 88------------------------------------------------------------\n19/20 train_loss: 0.592688, train_acc: 75.000000\nEnd of 88 train_loss: 0.5927, train_acc: 75.0000, val_loss: 0.2727, val_acc: 91.8750, f1_score: 0.8989\nnew best model saved.\nEpoch 89------------------------------------------------------------\n19/20 train_loss: 0.576426, train_acc: 75.781250\nEnd of 89 train_loss: 0.5764, train_acc: 75.7812, val_loss: 0.3083, val_acc: 89.0625, f1_score: 0.8729\nEpoch 90------------------------------------------------------------\n19/20 train_loss: 0.540358, train_acc: 77.916667\nEnd of 90 train_loss: 0.5404, train_acc: 77.9167, val_loss: 0.2604, val_acc: 91.2500, f1_score: 0.8966\nEpoch 91------------------------------------------------------------\n19/20 train_loss: 0.591948, train_acc: 77.656250\nEnd of 91 train_loss: 0.5919, train_acc: 77.6562, val_loss: 0.3396, val_acc: 90.0000, f1_score: 0.8897\nEpoch 92------------------------------------------------------------\n19/20 train_loss: 0.526583, train_acc: 79.375000\nEnd of 92 train_loss: 0.5266, train_acc: 79.3750, val_loss: 0.3081, val_acc: 89.5312, f1_score: 0.8667\nEpoch 93------------------------------------------------------------\n19/20 train_loss: 0.537661, train_acc: 79.270833\nEnd of 93 train_loss: 0.5377, train_acc: 79.2708, val_loss: 0.2872, val_acc: 91.0938, f1_score: 0.8986\nEpoch 94------------------------------------------------------------\n19/20 train_loss: 0.522713, train_acc: 79.791667\nEnd of 94 train_loss: 0.5227, train_acc: 79.7917, val_loss: 0.2461, val_acc: 92.6562, f1_score: 0.9164\nnew best model saved.\nEpoch 95------------------------------------------------------------\n19/20 train_loss: 0.577487, train_acc: 76.718750\nEnd of 95 train_loss: 0.5775, train_acc: 76.7188, val_loss: 0.3131, val_acc: 89.6875, f1_score: 0.8818\nEpoch 96------------------------------------------------------------\n19/20 train_loss: 0.551269, train_acc: 77.187500\nEnd of 96 train_loss: 0.5513, train_acc: 77.1875, val_loss: 0.2305, val_acc: 92.8125, f1_score: 0.9143\nnew best model saved.\nEpoch 97------------------------------------------------------------\n19/20 train_loss: 0.528398, train_acc: 78.906250\nEnd of 97 train_loss: 0.5284, train_acc: 78.9062, val_loss: 0.2656, val_acc: 91.0938, f1_score: 0.8983\nEpoch 98------------------------------------------------------------\n19/20 train_loss: 0.508851, train_acc: 79.583333\nEnd of 98 train_loss: 0.5089, train_acc: 79.5833, val_loss: 0.2255, val_acc: 92.1875, f1_score: 0.9080\nEpoch 99------------------------------------------------------------\n19/20 train_loss: 0.493448, train_acc: 79.531250\nEnd of 99 train_loss: 0.4934, train_acc: 79.5312, val_loss: 0.2507, val_acc: 91.2500, f1_score: 0.9014\nEpoch 100------------------------------------------------------------\n19/20 train_loss: 0.536624, train_acc: 79.947917\nEnd of 100 train_loss: 0.5366, train_acc: 79.9479, val_loss: 0.2435, val_acc: 94.2188, f1_score: 0.9353\nnew best model saved.\nTraining ended with 100 epochs.\nLoading best checkpoints from ./saved_models/best_checkpoint.pt\nEvaluation Results: test_loss:0.24347861111164093, test_acc:94.21875, test_f1:0.9352771084337349\n","output_type":"stream"}],"execution_count":108}]}